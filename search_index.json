[
["index.html", "Elementi di R e Radiant per un primo corso di Statistica Premessa", " Elementi di R e Radiant per un primo corso di Statistica Sergio Venturini sergio.venturini@unibocconi.it 2018-07-27 Premessa In questo manuale illustriamo sinteticamente le funzionalità ed i comandi R che sono presentati nel corso 30001 (Statistica) dell’Università Commerciale “L. Bocconi”. Poiché la sintassi dei numerosi comandi di R può talvolta rivelarsi complessa, per semplificare la presentazione e lo studio da parte degli studenti abbiamo deciso di avvalerci dell’uso di un pacchetto (ovvero di una “estensione” di R), chiamato Radiant, che fornisce un’interfaccia grafica (via browser) per buona parte delle tecniche illustrate durante il corso. Tale approccio ci consentirà di presentare un maggior numero di esempi e di dedicare più tempo all’interpretazione dei risultati. Solo in alcune situazioni, descritte in dettaglio in questo manuale, utilizzeremo direttamente il codice R, poiché in tali contesti Radiant non fornisce strumenti sufficientemente adeguati ai nostri scopi. Il manuale è diviso in cinque capitoli più un’appendice. Nel primo capitolo descriviamo come installare R e Radiant, alcuni principi di base per l’uso di questi software e le modalità principali per ottenere informazioni sui vari comandi (il cosiddetto “help” di R). Nei successivi capitoli mostreremo invece come svolgere le analisi oggetto del corso. Più nello specifico, nel secondo capitolo ci concentreremo sulle tecniche descrittive, con particolare enfasi sulla visualizzazione dei dati. Nel terzo capitolo, il più breve del manuale, presenteremo i comandi utili per svolgere calcoli probabilistici. Nel capitolo quattro sarà la volta delle tecniche inferenziali, ovvero degli strumenti di stima e prova delle ipotesi. Dedicheremo invece il quinto capitolo alla presentazione dei comandi per l’analisi di regressione lineare. L’appendice finale contiene ulteriori dettagli per chi fosse interessato ad approfondire l’uso diretto di R, ovvero senza l’interfaccia fornita da Radiant, cosa questa che può tornare utile anche in vista di corsi futuri. Siamo fermamente convinti che l’apprendimento della statistica non possa prescindere dalla presentazione di strumenti di calcolo adeguati per l’applicazione delle varie analisi a situazioni concrete. Questa è la principale motivazione che ci ha guidati nella preparazione del materiale per il vostro corso di statistica e di questo manuale. Speriamo di essere riusciti nel nostro intento. Buona lettura! \\(\\ddot\\smile\\) "],
["introduzione.html", "Capitolo 1 Introduzione", " Capitolo 1 Introduzione In questo capitolo presentiamo alcuni concetti preliminari necessari per introdurre i comandi descritti nei capitoli successivi. Una lettura attenta di questo primo capitolo è di fondamentale importanza sia per seguire il corso sia per il superamento dell’esame. Pertanto, è bene che prepariate il vostro laptop sin dalle primissime lezioni. Vi suggeriamo di seguire in modo molto dettagliato le istruzioni qui riportate per l’installazione dei vari software. Nel caso non siate riusciti ad installare tutti i componenti necessari, vi invitiamo a chiedere un supporto operativo all’ICT dell’Università. Per gli aspetti più specifici riguardanti l’uso di R potete invece rivolgervi direttamente ai docenti della vostra classe. "],
["installazione-dei-software.html", "1.1 Installazione dei software", " 1.1 Installazione dei software Per poter utilizzare i comandi descritti nel resto del manuale è necessario scaricare e installare nell’ordine qui presentato i seguenti software: l’applicazione R (http://www.r-project.org) l’applicazione RStudio (http://www.rstudio.com) il pacchetto Radiant (https://vnijs.github.io/radiant) Banalizzando un po’, possiamo dire che la prima componente, R, rappresenta il motore della nostra macchina per le analisi statistiche, senza il quale non si va da nessuna parte. La seconda componente, RStudio, rappresenta la plancia di comando dell’auto con cui possiamo controllare e regolare la potenza del motore. Infine, la terza componente, ovvero Radiant, costituisce la carrozzeria esterna dell’auto, la quale conferisce all’auto un aspetto più gradevole e meno tecnico rispetto alla complicata meccanica interna. Come abbiamo già accennato nella premessa a questo manuale, non sarebbe strettamente necessario installare tutte queste componenti, in quanto basterebbe solo la prima, R. Tuttavia, non essendo R dotato di un’interfaccia grafica, il suo utilizzo non è sempre intuitivo. Per questo motivo abbiamo deciso di semplificarne l’apprendimento introducendo altre componenti software che rendono più gestibile l’uso di R come motore di calcolo. Tutti i software che utilizzeremo sono open-source, ovvero liberamente scaricabili un numero illimitato di volte. Nelle prossime sezioni riportiamo le istruzioni per l’installazione dei software separatamente per computer con sistema operativo Windows o Mac. Le pagine web a cui ci riferiamo nelle prossime pagine non sono statiche ma vengono modificate e aggiornate periodicamente. Quindi, le istruzioni qui riportate potrebbero subire cambiamenti anche nell’immediato futuro. Inoltre, le schermate che mostreremo in questo manuale sono state create su un computer Mac impostato in lingua inglese. A parte alcune piccole differenze grafiche, le informazioni fornite valgono esattamente allo stesso modo anche nel caso usaste un computer Windows o aveste le applicazioni impostate in un’altra lingua. 1.1.1 Installazione su Windows Le istruzioni qui riportate si riferiscono all’ultima versione disponibile di Windows, ovvero la 101. 1.1.1.1 Download e installazione di R Aprite il vostro browser e andate sulla home page del Comprehensive R Archive Network (CRAN), che trovate all’indirizzo https://cran.r-project.org (si veda la Figura 1.1). Figura 1.1: Pagina iniziale del CRAN. Fate click sul link Download R for Windows e sarete reindirizzati alla pagina web mostrata in Figura 1.2. Figura 1.2: Pagina del CRAN da cui scaricare la versione di R per Windows. Quindi, fate click sul link install R for the first time e vi sarà mostrata la pagina che vedete in Figura 1.3. Figura 1.3: Pagina del CRAN da cui scaricare R nel caso sia la prima volta che viene installato su Windows. Fate click sul link Download R 3.5.1 for Windows. Questa operazione scaricherà un file eseguibile chiamato R 3.5.1-win.exe2. Una volta scaricato, fate doppio click sul file appena scaricato. In Windows 10, comparirà un messaggio di warning: “Windows protected your PC. Windows SmartScreen prevented an unrecognized app from starting. Running this app might put your PC at risk”. Fate click su More info e poi sul pulsante Run anyway. Windows fornisce questo warning se le impostazioni del vostro account utente sono quelle di default e state scaricando software che non proviene dal Windows App Store ufficiale. Durante la procedura di installazione vi consigliamo di usare le impostazioni di default proposte. Una volta installato, lanciate R come ogni altro software (per esempio, facendo doppio click sull’icona sul desktop, o selezionandolo dal manu Start di Windows). Se state utilizzando R su un computer con sistema operativo Windows a 64-bit (praticamente tutti i computer attuali), troverete che sono state installate entrambe le versioni a 64 e 32-bit. Potete usare l’una o l’altra, ma vi suggeriamo di usare la versione a 64-bit (potreste anche eliminare dal vostro desktop l’icona di quella a 32-bit). 1.1.1.2 Download e installazione di RStudio RStudio è un tipo di applicazione che i programmatori chiamano integrated development environment (IDE), ovvero un ambiente di sviluppo per R. Un IDE è una cosa diversa da un’interfaccia grafica (graphical user interface, GUI), la quale fornisce uno strumento per interagire con un’applicazione e visualizzarne gli output. Come abbiamo detto, non sarebbe strettamente necessario passare per l’installazione di RStudio, ma ciò rende più agevole l’utilizzo degli strumenti di cui parleremo successivamente. Aprite il browser e andate sulla home page di RStudio collegandovi all’indirizzo https://www.rstudio.com (si veda la Figura 1.4). Figura 1.4: Pagina iniziale del sito di RStudio. Cliccate su Download RStudio nel banner iniziale spostandovi così nella pagina riportata in Figura 1.5 Figura 1.5: Pagina per il download di RStudio. Cliccate quindi sul pulsante di download relativo a RStudio Desktop Open Source License, la versione gratuita (si veda la Figura 1.6) Figura 1.6: Pagina per il download di RStudio. Cliccate infine sul link RStudio 1.1.456 - Windows Vista/7/8/10, con cui scaricherete un file eseguibile denominato RStudio 1.1.456.exe3. Una volta scaricato, fate doppio click sul file ed eseguite l’installazione. Una volta installato, lanciate RStudio come ogni altro software (per esempio, facendo doppio click sull’icona sul desktop, o selezionandolo dal manu Start di Windows). 1.1.1.3 Installazione di Radiant Le funzioni di R sono organizzate in pacchetti che fanno riferimento a specifiche tipologie di analisi. R viene fornito con un insieme base di pacchetti che consentono di effettuare le più comuni analisi statistiche. Tuttavia, è possibile ampliare le funzionalità base di R installando pacchetti aggiuntivi (i cosiddetti contributed packages). Radiant è di uno di questi pacchetti, il quale fornisce una GUI basata su browser per un buon numero di funzioni di R. La pagina web di Radiant si trova all’indirizzo https://vnijs.github.io/radiant (vedi Figura 1.7), da cui è possibile reperire tutte le informazioni sull’installazione e sull’uso del pacchetto. In questo manuale presenteremo solo le funzionalità di Radiant (così come di R e RStudio) che sono rilevanti per il nostro corso. Figura 1.7: Home page del pacchetto Radiant. Per installare Radiant è necessario avviare RStudio e nella finestra denominata Console (ovvero nella finestra che si trova nella metà sinistra dell’applicazione; si veda la Figura 1.14) è necessario digitare il seguente comando4: &gt; install.packages(&quot;radiant&quot;, repos = &quot;https://radiant-rstats.github.io/minicran/&quot;, type = &#39;binary&#39;) Questo comando scaricherà ed installerà non solo Radiant, ma anche una serie di altri pacchetti da cui Radiant dipende. Alla fine dell’installazione potete avviare Radiant eseguendo nella Console il comando &gt; radiant::radiant() o alternativamente scegliendo il comando Start radiant (browser) che si trova cliccando sul pulsante Addins nella barra degli strumenti di RStudio. Una volta avviato, Radiant aprirà il vostro browser predefinito e mostrerà la schermata riportata in Figura 1.8. Per interrompere la sessione di lavoro in Radiant è sufficiente scegliere Stop dal menu che riporta il simbolo di on/off nella barra dei menu in alto. Figura 1.8: Schermata di avvio del pacchetto Radiant. La pagina web https://radiant-rstats.github.io/docs/tutorials.html contiene una serie di video tutorial su come installare ed utilizzare Radiant. 1.1.2 Installazione su Mac 1.1.2.1 Download e installazione di R Aprite il vostro browser e andate sulla home page del Comprehensive R Archive Network (CRAN), che trovate all’indirizzo https://cran.r-project.org (si veda la Figura 1.1). Fate click sul link Download R for (Mac) OS X e sarete reindirizzati alla pagina web mostrata nella Figura 1.9. Figura 1.9: Pagina del CRAN da cui scaricare la versione di R per Mac. Fate click sul link R 3.5.1.pkg5. Questa operazione scaricherà un file eseguibile chiamato R 3.5.1.pkg. Una volta scaricato, fate doppio click sul file ed eseguite l’installazione. Durante la procedura di installazione vi consigliamo di usare le impostazioni di default proposte. Una volta installato, lanciate R come ogni altro software (tipicamente facendo doppio click sulla sua icona nella cartella Applicazioni). 1.1.2.2 Download e installazione di RStudio RStudio è un tipo di applicazione che i programmatori chiamano integrated development environment (IDE), ovvero un ambiente di sviluppo per R. Un IDE è una cosa diversa da un’interfaccia grafica (graphical user interface, GUI), la quale fornisce uno strumento per interagire con un’applicazione e visualizzarne gli output. Come abbiamo detto, non sarebbe strettamente necessario passare per l’installazione di RStudio, ma ciò rende più agevole l’utilizzo degli strumenti di cui parleremo successivamente. Aprite il browser e andate sulla home page di RStudio collegandovi all’indirizzo https://www.rstudio.com (si veda la Figura 1.4). Cliccate su Download RStudio nel banner iniziale spostandovi così nella pagina riportata in Figura 1.5 Cliccate quindi sul pulsante di download relativo a RStudio Desktop Open Source License, la versione gratuita (si veda la Figura 1.6) Cliccate infine sul link RStudio 1.1.456 - Mac OS X 10.6+ (64-bit), con cui scaricherete un file eseguibile denominato RStudio 1.1.456.dmg6. Una volta scaricato, fate doppio click sul file appena scaricato ed eseguite l’installazione. Una volta installato, lanciate RStudio come ogni altro software, ovvero facendo doppio click sull’icona nella cartella Applicazioni. 1.1.2.3 Installazione di Radiant Le funzioni di R sono organizzate in pacchetti che fanno riferimento a specifiche tipologie di analisi. R viene fornito con un insieme base di pacchetti, che consentono di effettuare le più comuni analisi statistiche. Tuttavia, è possibile ampliare le funzionalità base di R installando pacchetti aggiuntivi (i cosiddetti contributed packages). Radiant è di uno di questi pacchetti, il quale fornisce una GUI basata su browser per un buon numero di funzioni di R. La pagina web di Radiant si trova all’indirizzo https://vnijs.github.io/radiant (vedi Figura 1.7), da cui è possibile reperire tutte le informazioni sull’installazione e sull’uso del pacchetto. In questo manuale presenteremo solo le funzionalità di Radiant (così come di R e RStudio) che sono rilevanti per il nostro corso. Per installare Radiant è necessario avviare RStudio e nella finestra denominata Console (ovvero nella finestra che si trova nella metà sinistra dell’applicazione) è necessario digitare il seguente comando7: &gt; install.packages(&quot;radiant&quot;, repos = &quot;https://radiant-rstats.github.io/minicran/&quot;, type = &#39;binary&#39;) Questo comando scaricherà ed installerà non solo Radiant, ma anche una serie di altri pacchetti da cui Radiant dipende. Alla fine dell’installazione potete avviare Radiant eseguendo nella Console il comando &gt; radiant::radiant() o alternativamente scegliendo il comando Start radiant (browser) che si trova nel menu Addins nella barra degli strumenti di RStudio. Una volta avviato, Radiant aprirà il vostro browser predefinito e mostrerà la schermata riportata in Figura 1.8. Per interrompere la sessione di lavoro in Radiant è sufficiente scegliere Stop dal menu che riporta il simbolo di on/off nella barra dei menu in alto. La pagina web https://radiant-rstats.github.io/docs/tutorials.html contiene una serie di video tutorial su come installare ed utilizzare Radiant. E’ molto probabile che le stesse istruzioni funzionino anche con versioni precedenti di Windows, ma non siamo in grado di garantirlo al 100%.↩ Per tutta la durata del corso suggeriamo di utilizzare la versione 3.5.1. Pertanto, anche se fossero disponibili versioni successive, vi invitiamo ad installare sempre questa versione (le versioni precedenti di R possono essere recuperate cliccando sul link Previous releases visibile anche in Figura 1.3).↩ Vi ricordiamo ancora una volta che la versione che troverete nel momento in cui vi collegherete a questa pagina potrebbe essere diversa da quella qui riportata.↩ Se doveste copiare e incollare il codice nella console, ricordatevi di cancellare il simbolo iniziale &gt;, che indentifica la cosiddetta riga di comando, ovvero il punto in cui inserire i comandi che si vogliono eseguire.↩ Ribadiamo ancora una volta che la versione di R disponibile al momento del download potrebbe essere successiva alla 3.5.1. Tuttavia, per tutta la durata del corso suggeriamo di utilizzare la versione 3.5.1. Pertanto, anche se fossero disponibili versioni successive, vi invitiamo ad installare sempre questa versione (le versioni precedenti di R per Mac possono essere recuperate all’indirizzo https://cran.r-project.org/bin/macosx/el-capitan/base/).↩ Ricordiamo ancora una volta che la versione che troverete nel momento in cui vi collegherete a questa pagina potrebbe essere diversa da quella qui riportata.↩ Se doveste copiare e incollare il codice nella console, ricordatevi di cancellare il simbolo iniziale &gt;, che indentifica la cosiddetta riga di comando, ovvero il punto in cui inserire i comandi che si vogliono eseguire.↩ "],
["lapproccio-al-calcolo-statistico-di-r.html", "1.2 L’approccio al calcolo statistico di R", " 1.2 L’approccio al calcolo statistico di R R è un software open-source che fornisce un linguaggio di scripting per la statistica e il data science a 360°. Ad oggi è considerato lo strumento più completo e avanzato per svolgere tutte le analisi che il data science e i Big Data richiedono. Non a caso, infatti, tutti i software statistici commerciali disponibili sul mercato come SPSS, SAS, ecc., offrono oggi la possibilità di interfacciarsi con R per integrare le proprie funzionalità con quelle molto più ampie di R. R è un linguaggio per la manipolazione di “oggetti”. Molto spesso si dice infatti che in R “tutto è un oggetto”. In senso lato, gli oggetti sono strumenti per l’organizzazione di diversi tipi di informazioni. Possiamo pensare agli oggetti come a dei contenitori la cui dimensione e tipo dipende dal suo contenuto. R fornisce molti strumenti per creare, visualizzare e manipolare gli oggetti che ci servono per effettuare le analisi. Per capire cosa intendiamo con tutto ciò, vi suggeriamo di aprire RStudio e di digitare la seguente riga di codice al prompt dei comandi: &gt; x &lt;- 5 Il simbolo &gt; rappresenta il prompt dei comandi e non deve essere copiato per l’esecuzione del codice. Una volta digitato, il comando viene eseguito premendo il pulsante INVIO.Il simbolo &lt;-, che corrisponde ai caratteri &lt; (minore di) e - (segno meno), rappresenta l’operatore di assegnazione, ovvero l’operatore con cui vengono creati nuovi oggetti8. Nel precedente esempio abbiamo creato un nuovo oggetto, che abbiamo deciso di chiamare x, ma che avremmo potuto chiamare in qualsiasi altro modo, il quale contiene semplicemente il numero 5. Se la sintassi del comando che eseguiamo è corretta, R non produce messaggi, come nell’esempio sopra. Ciò significa che il comando digitato non presenta errori sintattici. Per poter visualizzare il contenuto di un oggetto è sufficiente scrivere il nome dell’oggetto e premere INVIO: &gt; x [1] 5 Per avere informazioni sulla struttura (ovvero sulle caratteristiche) di un oggetto, ma senza visualizzarne completamente il contenuto, possiamo usare la funzione str(), ad esempio &gt; str(x) num 5 L’output restituito ci informa sul fatto che l’oggetto x contiene un numero (num). La funzione str() può essere usata per ottenere informazioni sulla struttura di qualsiasi oggetto creato in R. Come ulteriore esempio eseguiamo il codice seguente9: &gt; txt &lt;- c(&quot;R&quot;, &quot;è&quot;, &quot;un&quot;, &quot;software&quot;, &quot;per&quot;, &quot;il&quot;, &quot;data&quot;, &quot;science&quot;) &gt; str(txt) chr [1:8] &quot;R&quot; &quot;è&quot; &quot;un&quot; &quot;software&quot; &quot;per&quot; &quot;il&quot; ... In questo caso abbiamo creato un nuovo oggetto chiamato txt che contiene un vettore di 8 stringhe di testo (il termine chr che appare all’inizio della riga in output indica che il contenuto dell’oggetto è di questo tipo). L’output della funzione str() ci informa proprio di queste caratteristiche. c() è la funzione per creare un vettore, ovvero un oggetto con una sola dimensione che può contenere elementi dello stesso tipo, in questo caso stringhe di testo10. Se desiderate mostrare la lista degli oggetti creati finora, potete usare la funzione ls() &gt; ls() [1] &quot;txt&quot; &quot;x&quot; Ricordiamo che R è case sensitive, ovvero distingue tra caratteri maiuscoli e minuscoli. Infine, se create un nuovo oggetto usando il nome di un oggetto già esistente, chiaramente perderete il vecchio oggetto, il cui contenuto sarà sostituito con quello del nuovo oggetto, ad esempio: &gt; y &lt;- c(3, 4, -1, 0) &gt; str(y) num [1:4] 3 4 -1 0 &gt; y &lt;- &quot;Viva la Statistica!&quot; &gt; str(y) chr &quot;Viva la Statistica!&quot; Al posto del simbolo &lt;- è possibile usare il segno di uguale (=), ma per tradizione in R si tende ad utilizzare sempre il primo.↩ Gli spazi prima e dopo le virgole o gli operatori non sono strettamente necessari, ma contribuiscono a rendere il codice più leggibile.↩ Una stringa di testo è caratterizzata dal fatto di essere inclusa tra virgolette.↩ "],
["le-principali-strutture-di-dati-disponibili-in-r.html", "1.3 Le principali strutture di dati disponibili in R", " 1.3 Le principali strutture di dati disponibili in R Come abbiamo già detto, in R esistono tipi diversi di oggetti e in questa sezione daremo una breve descrizione di quelli che ci serviranno nel resto del manuale. 1.3.1 Tipi di dati di base In R è possibile creare oggetti contenenti dati numerici, testuali o logici, che in R sono indicati rispettivamente come num, chr e logical11. Abbiamo già visto esempi di dati numerici e testuali, mentre i dati di tipo logico sono di solito ottenuti come risultato della verifica di una o più condizioni logiche. Ad esempio, dopo aver definito il vettore \\(x = (10, -2, 0.3, -1, 5)\\), ovvero &gt; x &lt;- c(10, -2, 0.3, -1, 5) supponiamo di voler verificare quali dei suoi elementi siano positivi e quali no. Per farlo è sufficiente eseguire il seguente codice, in cui il risultato della verifica viene memorizzato nel nuovo oggetto z: &gt; z &lt;- (x &gt; 0) &gt; z [1] TRUE FALSE TRUE FALSE TRUE &gt; str(z) logi [1:5] TRUE FALSE TRUE FALSE TRUE Come vediamo, z contiene la risposta alla nostra domanda, risposta che viene data sotto forma di un vettore di valori TRUE e FALSE a seconda che i vari elementi di x siano positivi o negativi. 1.3.2 Vettori Si tratta della struttura di dati più importante in R rappresentata da un insieme di elementi tutti dello stesso tipo, ovvero numeri, stringhe di testo o valori logici. Abbiamo già visto nei precedenti esempi che possiamo creare un vettore con la funzione c(), la quale consente di concatenare più elementi in un unico oggetto. Molte funzioni di R restituiscono in output dei vettori, pertanto è importante imparare bene a manipolare questo tipo di oggetti. La funzione length() restituisce la dimensione di un vettore, ovvero il numero di elementi che lo compongono: &gt; length(z) [1] 5 Per selezionare uno o più elementi di un vettore dobbiamo usare l’operatore [] (parentesi quadre). Ad esempio, possiamo estrarre il terzo elemento del vettore x con il codice &gt; x[3] [1] 0.3 dove il numero 3 nelle parentesi quadre sta ad indicare la posizione dell’elemento che vogliamo estrarre. Allo stesso modo possiamo selezionare un sottoinsieme qualsiasi di elementi usando la funzione c(). Per estrarre da x gli elementi con posizione 1, 4 e 5 possiamo eseguire il codice &gt; w &lt;- x[c(1, 4, 5)] &gt; w [1] 10 -1 5 Notate come in questo caso abbiamo estratto un sottoinsieme di elementi, il cui risultato è stato immediatamente memorizzato in un nuovo oggetto che abbiamo chiamato w. In R è piuttosto comune, infatti, creare nuovi oggetti come risultato di una qualche operazione su oggetti già esistenti. Possiamo indicare quali elementi estrarre anche attraverso la verifica di condizioni logiche. Ad esempio, il codice seguente consente di estrarre da x solo gli elementi pari: &gt; x[(x %% 2) == 0] [1] 10 -2 Notate che in questo esempio abbiamo usato due operatori nuovi, l’operatore %% che restituisce il resto della divisione per il numero che si trova a destra dell’operatore (in questo caso, il resto della divisione di ognuno degli elementi di x per 2), e l’operatore logico ==, il quale invece verifica se il lato di sinistra è uguale a quello di destra e restituisce i valori logici TRUE o FALSE a seconda dei casi12. Ne approfittiamo anche per sottolineare che R applica automaticamente le varie operazioni a tutti gli elementi di un vettore. E’ possibile assegnare dei nomi agli elementi di un vettore attraverso la funzione names(). Ciò consente di riferirsi agli elementi del vettore attraverso i loro nomi invece che le loro posizioni: &gt; x [1] 10.0 -2.0 0.3 -1.0 5.0 &gt; names(x) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) &gt; x A B C D E 10.0 -2.0 0.3 -1.0 5.0 &gt; x[c(&quot;B&quot;, &quot;E&quot;, &quot;A&quot;)] B E A -2 5 10 La funzione names() può essere usata sia per ottenere i nomi degli elementi di un vettore, ma anche, come abbiamo fatto sopra, per assegnare i nomi agli elementi stessi. Concludiamo questa parte sui vettori aggiungendo che quando si lavora con data set veri è molto frequente che alcuni dei dati siano mancanti. Il codice che in R indica i dati mancanti è NA, acronimo di not available (corrisponde a una cella vuota in Excel). Supponiamo ad esempio che in una ricerca di mercato abbiamo raccolto i seguenti dati sul reddito annuo (in migliaia di euro) per un campione di 10 individui: &gt; income &lt;- c(40, 55, 60, NA, 34, 89, NA, NA, 121, 73) Tre degli individui intervistati non hanno comunicato il proprio reddito e pertanto sono riportati come NA. Per sapere quali dati sono mancanti possiamo usare la funzione is.na(), che restituisce un vettore logico di lunghezza pari a quella del vettore a cui è applicata: &gt; is.na(income) [1] FALSE FALSE FALSE TRUE FALSE FALSE TRUE TRUE [9] FALSE FALSE Per contare quanti dati sono mancanti possiamo usare la funzione sum(), la quale in generale consente di calcolare la somma degli elementi di un vettore. In questo caso sum() converte prima i valori logici TRUE e FALSE restituiti da is.na() rispettivamente in 1 e 0, e quindi ne calcola la somma: &gt; sum(is.na(income)) [1] 3 1.3.3 Matrici Altre strutture di dati utili in R sono le matrici, ovvero insiemi di elementi dello stesso tipo (numeri, testo, valori logici) disposti lungo due dimensioni, righe e colonne, invece che lungo una sola dimensione come per i vettori. Per creare una matrice usiamo la funzione matrix(), la quale è più articolata rispetto alle funzioni che abbiamo usato finora, perché richiede diversi argomenti (per una discussione più dettagliata sulle caratteristiche di un oggetto di tipo funzione e una descrizione del tipo di argomenti che è possibile passare ad una funzione, si veda la Sezione 1.3.713). Il primo argomento richiesto, denominato data, corrisponde al vettore di elementi della matrice riportati indifferentemente per riga o per colonna. Il secondo e terzo argomento, denominati rispettivamente nrow e ncol, indicano il numero di righe e di colonne in cui gli elementi in data vogliamo vengano disposti. Il quarto argomento, denominato byrow, serve per indicare ad R se la matrice deve essere riempita per righe (TRUE) o per colonne (FALSE). Nell’esempio che segue creiamo una matrice \\((3 \\times 2)\\) procedendo per righe: &gt; A &lt;- matrix(data = c(4, 2, 0, 1, -3, 0.9), nrow = 3, ncol = 2, byrow = TRUE) &gt; A [,1] [,2] [1,] 4 2.0 [2,] 0 1.0 [3,] -3 0.9 &gt; str(A) num [1:3, 1:2] 4 0 -3 2 1 0.9 La funzione dim() restituisce un vettore con le dimensioni della matrice. Per estrarre un sottoinsieme di elementi da una matrice abbiamo a disposizione le stesse modalità che abbiamo descritto per i vettori, salvo che ora all’interno delle parentesi quadre sarà necessario indicare sia gli indici di riga sia quelli di colonna degli elementi da estrarre. Nel caso si intenda estrarre tutte le righe o tutte le colonne di una matrice, è sufficiente non indicare il rispettivo vettore di indici. Il seguente codice mostra due esempi usando la matrice A definita sopra14: &gt; A[2, 1] # elemento in riga 2 e colonna 1 [1] 0 &gt; A[c(1, 3), 2] # elementi in riga 1 o 3 e in colonna 2 [1] 2.0 0.9 &gt; A[, 1] # tutti gli elementi della prima colonna [1] 4 0 -3 Provate ora un piccolo esercizio (verificate poi la risposta eseguendo il codice): quali sono gli elementi della matrice A selezionati dal seguente codice? &gt; A[A[, 2] &gt;= 1, A[3, ] &lt; 0] E’ possibile attribuire dei nomi anche agli elementi di una matrice. Visto che ora ci sono due dimensioni, esistono due funzioni, chiamate rownames e colnames, per assegnare dei nomi rispettivamente alle righe o alle colonne della matrice: &gt; rownames(A) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) &gt; colnames(A) &lt;- c(&quot;d&quot;, &quot;e&quot;) &gt; A d e a 4 2.0 b 0 1.0 c -3 0.9 Dopo aver assegnato i nomi a righe e colonne, possiamo ad esempio selezionare la terza riga della matrice A come segue &gt; A[&quot;c&quot;, ] d e -3.0 0.9 E’ possibile unire matrici e vettori affiancandone i rispettivi elementi lungo una delle due dimensioni (righe o colonne) attraverso le funzioni rbind() (per affiancare le righe) e cbind() (per affiancare le colonne): &gt; D &lt;- matrix(c(1, 0, 0, 1), nrow = 2, ncol = 2, byrow = TRUE) &gt; b &lt;- c(-3, 4, 0) &gt; &gt; rbind(A, D) d e a 4 2.0 b 0 1.0 c -3 0.9 1 0.0 0 1.0 &gt; cbind(A, b) d e b a 4 2.0 -3 b 0 1.0 4 c -3 0.9 0 1.3.4 Vettori factor Un vettore factor è un vettore che contiene solo valori predefiniti ed è utilizzato per rappresentare delle variabili qualitative/categoriche. I vettori factor sono definiti internamente da R a partire da numeri interi a cui vengono poi “appiccicate” delle etichette di testo. Per creare un vettore factor si usa la funzione factor(). Supponiamo per esempio che nell’ipotetico sondaggio che abbiamo descritto nella Sezione 1.3.2, oltre al reddito annuo abbiamo raccolto anche il genere degli intervistati, riportati rispettivamente come &quot;m&quot; e &quot;f&quot;: &gt; gender &lt;- factor(c(&quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;)) &gt; gender [1] f f f m m f m f f m Levels: f m Per conoscere i livelli di un vettore factor si usa la funzione levels(): &gt; levels(gender) [1] &quot;f&quot; &quot;m&quot; I vettori factor si riveleranno di fondamentale importanza per l’analisi di dati categorici. 1.3.5 Data frame I data frame sono le strutture di dati tipicamente utilizzate in R per contenere un data set. Non sono da confondere con le matrici, poiché quest’ultime richiedono che i dati in esse contenute siano tutti dello stesso tipo, mentre i data frame possono contenere un misto di colonne numeriche, categoriche o testuali. Possiamo creare un data frame ex-novo attraverso la funzione data.frame(), anche se il sistema più comune per crearne uno consiste nell’importare dei dati già salvati precedentemente in un file (si veda la Sezione 1.8). A titolo di esempio, il codice seguente crea un data frame a partire dai vettori income e gender creati precedentemente, i quali diventeranno rispettivamente la prima e la seconda colonna del data frame: &gt; dat &lt;- data.frame(income, gender) &gt; str(dat) &#39;data.frame&#39;: 10 obs. of 2 variables: $ income: num 40 55 60 NA 34 89 NA NA 121 73 $ gender: Factor w/ 2 levels &quot;f&quot;,&quot;m&quot;: 1 1 1 2 2 1 2 1 1 2 Notate che la funzione str() restituisce una sintesi delle informazioni contenute nelle colonne del data frame, indicando per ognuna la corrispondente tipologia di dati, ovvero num e Factor con 2 livelli, &quot;f&quot; e &quot;m&quot;. Come per le matrici, la funzione dim() restituisce le dimensioni di un data frame (numero di osservazioni e numero di variabili), così come funziona allo stesso modo anche la selezione di un sottoinsieme di dati e l’assegnazione di nomi a righe e colonne: &gt; dat[5, 1] [1] 34 &gt; dat[, 2] [1] f f f m m f m f f m Levels: f m &gt; dat[c(1, 3, 4, 7), ] income gender 1 40 f 3 60 f 4 NA m 7 NA m &gt; rownames(dat) [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; &gt; colnames(dat) [1] &quot;income&quot; &quot;gender&quot; In aggiunta, possiamo selezionare una colonna di un data frame utilizzando l’operatore $ (simbolo di dollaro)15. Ad esempio, per calcolare la media dei redditi annui per gli individui inclusi nel data set possiamo eseguire il codice seguente: &gt; mean(dat$income, na.rm = TRUE) [1] 67.43 Facciamo notare che nel codice precedente abbiamo specificato due argomenti, il primo corrisponde alla variabile di cui vogliamo calcolare la media, mentre il secondo argomento (na.rm, opzionale) indica che, prima di calcolare la media, vogliamo rimuovere gli eventuali dati mancanti16. Nel caso in cui il data set fosse troppo grande e non fosse quindi agevole stamparne l’intero contenuto nella Console, possiamo visualizzarlo con la funzione View(). Per combinare tra loro diversi data frame è consigliabile usare la funzione data.frame() invece che cbind(). I data frame che vengono combinati devono avere lo stesso numero di righe. 1.3.6 Liste Le liste sono oggetti molto generali i cui elementi possono essere altri oggetti di qualsiasi tipo, incluse altre liste. Possiamo creare una lista con la funzione list(): &gt; X &lt;- list(y, txt, A) &gt; X [[1]] [1] &quot;Viva la Statistica!&quot; [[2]] [1] &quot;R&quot; &quot;è&quot; &quot;un&quot; &quot;software&quot; [5] &quot;per&quot; &quot;il&quot; &quot;data&quot; &quot;science&quot; [[3]] d e a 4 2.0 b 0 1.0 c -3 0.9 &gt; str(X) List of 3 $ : chr &quot;Viva la Statistica!&quot; $ : chr [1:8] &quot;R&quot; &quot;è&quot; &quot;un&quot; &quot;software&quot; ... $ : num [1:3, 1:2] 4 0 -3 2 1 0.9 ..- attr(*, &quot;dimnames&quot;)=List of 2 .. ..$ : chr [1:3] &quot;a&quot; &quot;b&quot; &quot;c&quot; .. ..$ : chr [1:2] &quot;d&quot; &quot;e&quot; Vi suggeriamo di pensare alle liste come a una generalizzazione dei vettori i cui elementi non sono vincolati ad essere dello stesso tipo. Per recuperare il numero di elementi inclusi in una lista dobbiamo usare la funzione length(), mentre per accedere ad uno dei suoi elementi è necessario usare l’operatore [[]] (doppia parentesi quadra)17: &gt; X[[1]] # primo elemento della lista X [1] &quot;Viva la Statistica!&quot; &gt; X[[3]] # terzo elemento della lista X d e a 4 2.0 b 0 1.0 c -3 0.9 &gt; X[[3]][3, 2] # elemento in riga 3 e colonna 2 per il terzo elemento di X [1] 0.9 Le liste sono molto importanti in R, perché sono spesso usate per memorizzare e organizzare i risultati di un’analisi, come ad esempio quelli restituiti dalla funzione lm(), che sarà discussa nel Capitolo 5. 1.3.7 Funzioni L’ultima tipologia di oggetti che consideriamo sono le funzioni. In quanto oggetti, anche le funzioni possono essere manipolate come tutti gli altri oggetti disponibili in R. Tuttavia, la manipolazione di funzioni rappresenta un argomento di programmazione avanzata che quindi non discuteremo in questa sede. Qui ci limiteremo a descrivere alcune caratteristiche delle funzioni che ci torneranno utili nel resto del manuale. Ogni funzione in R è caratterizzata da tre elementi: il corpo della funzione, ovvero il codice contenuto nella stessa l’ambiente in cui la funzione viene valutata la lista di argomenti, ovvero gli input della funzione Tralasciamo i dettagli sui primi due elementi, poiché non ci serviranno nel resto del corso, mentre diamo qualche informazione sulla lista di argomenti. Come abbiamo già detto, il compito di ogni funzione è quello di prendere in carico un elenco di argomenti (input), di utilizzare tali input per svolgere una serie di calcoli/operazioni e quindi di restituire un output. Alcune funzioni restituiscono un ouput numerico, altre un output grafico, altre ancora non restituiscono nulla ma producono degli effetti secondari. Ad esempio, le funzioni rownames() e colnames() non producono alcun risultato visibile, ma modificano i nomi delle righe e delle colonne di una matrice o di un data frame. Come abbiamo già avuto modo di verificare concretamente in alcuni esempi, l’output di una funzione può essere memorizzato in un nuovo oggetto, in modo da poterlo recuperare in un secondo momento senza dover eseguire nuovamente i calcoli contenuti nella funzione. Dei tre elementi sopra elencati, quello sicuramente più importante ai nostri fini è l’elenco di argomenti. Ad eccezione di pochi casi, come ad esempio la funzione str(), praticamente tutte le funzioni richiedono uno o più argomenti. Nel caso sia necessario indicare più argomenti, questi devono essere separati da una virgola (vedi l’esempio sulla funzione matrix() nella Sezione 1.3.3). Possiamo recuperare la lista completa di argomenti di una funzione con args(). Ad esempio, per la funzione var(), che calcola la varianza campionaria di un insieme di dati numerici, otteniamo &gt; args(var) function (x, y = NULL, na.rm = FALSE, use) NULL Questo esempio mostra che la funzione var() include 4 argomenti, x, y, na.rm e use, su cui per ora non forniamo ulteriori dettagli. Quindi, ogni argomento ha un nome (ad esempio, il terzo argomento di var() si chiama na.rm) e gli argomenti di una funzione sono presentati in un certo ordine (per var(), prima viene x, poi y, e così via). Quando vogliamo usare una funzione che richiede più argomenti, dobbiamo riuscire a far capire ad R i valori che devono essere usati per ognuno di essi. Per fare ciò abbiamo a disposizione le seguenti alternative: fornire gli argomenti indicando per ognuno il rispettivo nome; in questo caso non dobbiamo preoccuparci di elencare gli argomenti nell’ordine in cui vengono mostrati da args(), ma possiamo scriverli in qualsiasi ordine fornire gli argomenti senza indicarne il nome, ma in questo caso R si aspetta che l’ordine sia quello riportato da args() entrambe le modalità precedenti, fornendo alcuni argomenti con il loro nome e altri inserendoli con la loro posizione corretta; quest’ultima modalità è di solito quella più usata nella pratica Vediamo ora alcuni esempi attraverso il calcolo della varianza dei redditi annui dei 10 intervistati nell’ipotetico sondaggio descritto sopra: &gt; var(x = income, na.rm = TRUE) # modalità 1. --&gt; corretto [1] 907.6 &gt; var(na.rm = TRUE, x = income) # modalità 1. --&gt; corretto [1] 907.6 &gt; var(income, NULL, TRUE) # modalità 2. --&gt; corretto [1] 907.6 &gt; var(income, TRUE) # modalità 2. --&gt; errore! Error in var(income, TRUE): incompatible dimensions &gt; var(income, na.rm = TRUE) # modalità 3. --&gt; corretto [1] 907.6 &gt; var(TRUE, x = income) # modalità 3. --&gt; errore! Error in var(TRUE, x = income): incompatible dimensions Concludiamo questa introduzione sulle funzioni notando che non è obbligatorio fornire tutti gli argomenti di una funzione. Ad esempio, negli esempi precedenti con var() non abbiamo mai indicato l’argomento use. Ciò deriva dal fatto che quasi tutte le funzioni hanno alcuni argomenti obbligatori e altri che sono invece facoltativi. L’argomento x della funzione var() è ad esempio obbligatorio: se provaste ad eseguire il codice var(na.rm = TRUE) otterreste infatti un errore. Qualora non indicassimo esplicitamente i valori degli argomenti facoltativi, R ultilizzerebbe per questi un valore di default, ovvero quello indicato da args(). Per esempio, la var() ha solo il primo argomento obbligatorio, mentre gli altri sono facoltativi, con na.rm che assume valore di default uguale a FALSE18. Gli argomenti facoltativi, quindi, vanno esplicitamente indicati solo quando vogliamo assegnarli un valore diverso da quello di default. L’output restituito da una funzione può essere un oggetto di qualsiasi tipo (vettore, matrice, data frame, lista, o un’altra funzione), anche se alcune funzioni, in particolare quelle che producono output grafico, non restituiscono direttamente nessun oggetto. In realtà R distingue anche tra numeri interi (int) e numeri reali (num), ma questa distinzione non ha nessuna implicazione dal nostro punto di vista.↩ L’operatore == non è da confondere con il segno di uguale (=).↩ Per il momento anticipiamo solo che gli argomenti di una funzione si dividono in obbligatori e opzionali. Gli argomenti opzionali, come ad esempio byrow() nell’esempio che segue, assumono un valore di default nel caso non vengano esplicitamente indicati. I valori di default per gli argomenti opzionali di una funzione possono essere recuperati dall’help della funzione stessa (vedi la Sezione 1.4).↩ Il carattere # consente di inserire un commento, ovvero un testo usato per descrivere una parte di codice, ma che non sarà eseguito da R.↩ Un modo per potersi riferire direttamente alla colonna income senza dover specificare il data frame che la contiene consiste nell’uso della funzione attach(), che appunto rende disponibili le colonne di un data frame come oggetti indipendenti durante la sessione di lavoro corrente (la funzione detach() consente di ripristinare la situazione di partenza). Tuttavia, attach() va usata con estrema cautela perché è possibile che data frame diversi contengano variabili con lo stesso nome. Per questo motivo, non la useremo ulteriormente in questo manuale.↩ Se non aggiungessimo l’argomento na.rm in presenza di dati mancanti otterremmo NA come risultato. Questo è il modo previsto in R per renderci consapevoli del fatto che una variabile contiene dei dati mancanti.↩ Se usassimo le parentesi quadre singole, invece di estrarre direttamente il contenuto dell’elemento della lista selezionato otterremmo ancora una lista ma con un unico elemento corrispondente all’elemento selezionato. Se questa spiegazione non vi convince, provate ad eseguire il codice str(X[1]).↩ L’argomento y di var() assume valore di default NULL, che in R indica un oggetto vuoto, che non contiene nulla.↩ "],
["howtogethelp.html", "1.4 Come reperire informazioni sui comandi di R", " 1.4 Come reperire informazioni sui comandi di R Poiché in R esistono migliaia di comandi, ognuna con il proprio elenco di argomenti, è praticamente impossibile memorizzarli tutti. Ognuno dei comandi disponibili in R possiede una documentazione molto dettagliata. Esistono due modi per ottenere informazioni su un comando. Se si conosce il nome del comando, basta digitare il punto interrogativo (?) seguito dal nome della funzione stessa (provate ad esempio con ?var). Se state lavorando in RStudio19, questa operazione mostrerà l’help della funzione var() nel tab denominato Help (vedi Figura 1.10). Figura 1.10: Help della funzione var() come mostrato da RStudio. Le pagine di help delle funzioni sono tutte strutturate nello stesso modo e riportano le seguenti informazioni: nella sezione Description trovate una breve descrizione della funzione nella sezione Usage trovate la sintassi completa della funzione nella sezione Arguments sono elencati tutti gli argomenti, obbligatori e facoltativi, della funzione con l’indicazione dei valori di default di questi ultimi nella sezione Details sono riportati i dettagli tecnici dei calcoli svolti dalla funzione nella sezione Value viene descritto l’output restituito dalla funzione nella sezione Note trovate ulteriori note sulla funzione nella sezione References sono elencati dei riferimenti bibliografici nella sezione SeeAlso} si indicano altre funzioni collegate a quella di cui state leggendo l’help nella sezione Examples sono riportati alcuni esempi sull’uso della funzione La seconda situazione in cui possiamo trovarci è quella in cui non conosciamo il nome del comando che ci serve. In questo caso possiamo digitare un doppio punto interrogativo (??) seguito da una o più parole chiavi20. L’output proposto consiste in una lista di pagine di help in cui le parole chiavi indicate vengono menzionate. A titolo di esempio, provate ad eseguire il comando ??median. Se state lavorando direttamente in R, le pagine di help saranno mostrate nel browser se usate un computer Windows, oppure in una nuova finestra chiamata RHelp} se usate un computer Mac.↩ Nel caso indicassimo più di una parola chiave, è necessario includere queste tra virgolette.↩ "],
["packages.html", "1.5 I pacchetti di R", " 1.5 I pacchetti di R R viene fornito con un set molto ampio di funzioni organizzate in pacchetti (packages). In aggiunta a queste funzioni, è possibile aggiungere ulteriori funzionalità ad R installando dei pacchetti aggiuntivi. Questi pacchetti, sviluppati dalla community di utenti di R, sono tutti disponibili gratuitamente. Per poter utilizzare le funzioni contenute in un pacchetto è necessario dapprima installare il pacchetto e poi caricarlo in memoria. La prima operazione, l’installazione, deve essere effettuata una sola volta (oppure ogni volta che si installa nuovamente R sul proprio computer o su un nuovo computer), mentre la seconda, il caricamento, deve essere eseguito ogni volta che si apre R (o RStudio). Esistono varie modalità di installazione di un pacchetto21, ma qui presentiamo la più semplice22: in RStudio scegliete il comando Tools \\(\\rightarrow\\) Install Packages… e comparirà la finestra mostrata in Figura 1.11. Figura 1.11: Installazione di un pacchetto in RStudio. Nel box Packages scrivete il nome del pacchetto che vi interessa installare e verificate che sia selezionato il flag Install dependencies. Ad esempio, in Figura 1.12 è riportata la procedura per l’installazione del pacchetto Hmisc, che contiene una serie di funzioni per effettuare dei calcoli che altrimenti porterebbero via molto tempo se effettuate con le funzionalità base di R. Figura 1.12: Installazione del pacchetto Hmisc in RStudio. Dopo aver cliccato su Install, RStudio scaricherà ed installerà i file necessari (vedi Figura 1.13) Figura 1.13: Installazione del pacchetto Hmisc in RStudio. Una volta installato un pacchetto, per caricarlo è necessario selezionarlo nella lista denominata Packages (vedi Figura 1.15) che riporta l’elenco dei pacchetti installati nella vostra libreria locale di R23. Insieme al pacchetto selezionato saranno caricati anche i pacchetti da cui esso dipende. Ricordatevi che per installare un pacchetto dovete essere collegati ad Internet.↩ Un metodo alternativo per l’installazione dei pacchetti utilizza la funzione install.packages(), che avete già usato per installare il pacchetto Radiant (vedi la Sezione 1.1.1.3).↩ Un modo alternativo per caricare un pacchetto già installato consiste nell’utilizzare la funzione library() indicando al suo interno il nome del pacchetto che ci interessa usare. Se il pacchetto che vogliamo caricare non è tra quelli già installati, library genererà un errore.↩ "],
["lapplicazione-rstudio.html", "1.6 L’applicazione RStudio", " 1.6 L’applicazione RStudio RStudio è un IDE open-source che semplifica l’uso di R integrandone la documentazione e consentendo di organizzare in modo ordinato le analisi in progetti distinti. Le funzionalità fornite da RStudio sono davvero numerose e le sue potenzialità emergono in particolare qualora interessi sviluppare nuove funzioni o pacchetti. In questa sezione forniamo un’introduzione minima che ci consentirà di lavorare in modo più semplice con R. Quando lo avviamo, RStudio si presenta come in Figura 1.14. Figura 1.14: Schermata di avvio di RStudio. La parte di sinistra è occupata dalla Console di R in cui, come abbiamo già fatto molte volte finora, è possibile digitare i comandi che intendiamo eseguire e in cui viene stampato l’output prodotto dai comandi stessi. La parte di destra è invece divisa in due parti24. La parte destra superiore è occupata dai tab chiamati Environment e History25. Il primo riporta la lista degli oggetti creati fino a quel momento con alcune informazioni di sintesi per ognuno di essi, mentre il secondo conterrà l’elenco cronologico dei diversi comandi eseguiti fino a un certo punto, con la possibilità di eseguirli nuovamente o salvarli in un file per essere poi riutilizzati in un secondo momento. La parte inferiore contiene invece i seguenti tab: Files, che mostra il contenuto della directory corrente, con la possibilità di cambiarla cliccando semplicemente sul nome della stessa Plots, che riporterà sequenzialmente tutti i grafici prodotti durante la sessione di lavoro Packages, che elenca i package installati sul vostro computer e quelli che al momento sono caricati in memoria (indicati dalle spunte a fianco dei nomi dei pacchetti) Help, che mostra l’help delle funzioni Viewer, che non useremo, ma che permette di visualizzare altri tipi di output che RStudio è in grado di produrre, come documenti PDF o HTML Come abbiamo già detto, è possibile eseguire un comando alla volta digitandolo nella Console. Chiaramente questo non è un modo comodo di lavorare con R, poiché una volta chiuso RStudio le analisi svolte andranno perse. Per poter riutilizzare i comandi ed eseguire nuovamente le corrispondenti analisi in un secondo momento, è quindi consigliabile inserire i comandi in uno script, ovvero un file di testo, che possiamo salvare e utilizzare successivamente. Per creare un nuovo script scegliete File \\(\\rightarrow\\) New File \\(\\rightarrow\\) R Script. Questa operazione aprirà un nuovo tab temporaneamente chiamato Untitled1 (vedi Figura 1.15) Figura 1.15: Apertura di un nuovo script in RStudio. In questa finestra possiamo scrivere il codice che ci interessa, il quale può essere eseguito in tutto o in parte26, e può essere salvato in un file con estensione .R scegliendo File \\(\\rightarrow\\) Save As…. Tutte le finestre in RStudio si possono ridimensionare e spostare.↩ Il tab Connections che vedete nella figura potrebbe non essere visibile sul vostro computer. In questo caso, non preoccupatevi, perché non ci servirà.↩ Selezionate il codice che vi interessa eseguire e cliccate sull’icone Run. In alternativa, dopo aver selezionato il codice, potete premere i tasti Ctrl+INVIO su Windows o cmd+INVIO su Mac.↩ "],
["il-pacchetto-radiant.html", "1.7 Il pacchetto Radiant", " 1.7 Il pacchetto Radiant Radiant è un pacchetto di R che fornisce una GUI per molte delle funzioni di cui ci occuperemo in questo corso. Una volta installato Radiant come è stato descritto nelle sezioni 1.1.1.3 e 1.1.2.3, possiamo avviarlo eseguendo il comando &gt; radiant::radiant() La pagina di avvio di Radiant, riportata in Figura 1.16, mostra la schermata in cui è possibile caricare, modificare e salvare un data set. Figura 1.16: Schermata di avvio del pacchetto Radiant. All’avvio Radiant mostra un data set di esempio (chiamato diamonds). Ogni volta che si carica un data set, Radiant ne mostra una piccola porzione nella parte di output chiamata Data preview. Le schermate di Radiant, a cui si accede attraverso i menu mostrati in alto (Data, Design, Basics, ecc.), sono strutturate con una serie di controlli su sfondo grigio sulla sinistra, che cambiano in base al menu scelto, e con una serie di tab all’interno della schermata che consentono di effettuare le varie analisi. Ad esempio, la schermata inziale, a cui si può tornare in qualsiasi momento cliccando sul menu Data in alto a sinistra, include i tab Manage, View, Visualize, Pivot, Explore, Transform e Combine. Nei capitoli successivi vedremo il funzionamento di alcuni di questi menu. "],
["file-loading.html", "1.8 Come caricare e salvare un file in R e Radiant", " 1.8 Come caricare e salvare un file in R e Radiant R possiede sostanzialmente due formati di file in cui salvare i dati, i file con estensione .RData (a volte abbreviato in .rda) e quelli con estensione .rds. Senza addentrarci nelle differenze tecniche, ci basta osservare che nel primo tipo di file (.RData) è possibile salvare contemporaneamente un numero indefinito di oggetti, mentre nei file .rds possiamo salvare un singolo oggetto alla volta. In questo manuale utilizzeremo solo i file di tipo .RData. Per caricare in memoria il contenuto di un file .RData da RStudio è necessario scegliere File \\(\\rightarrow\\) Open File…, selezionare il file da aprire e confermare. In alternativa, è possibile cliccare sul nome del file nel tab Files e confermare. Un’ultima possibilità impiega la funzione load(). Se ad esempio volessimo caricare il file Forbes94.RData, che contiene alcuni dati sul ranking pubblicato dalla rivista Forbes nel 1994 sugli 800 CEO più pagati negli Stati Uniti, il codice da eseguire è: &gt; load(&quot;Forbes94.RData&quot;) Notate che il nome del file deve essere incluso tra virgolette, poiché si tratta di una stringa di testo. Se il file si trovasse in una directory diversa da quella corrente, è necessario cambiare prima la directory di lavoro27, oppure indicare tutto il percorso all’interno della funzione load() (sconsigliamo quest’ultima strada perché più complessa). Dopo aver caricato il file Forbes94.RData, nel tab Environment di RStudio troverete i nuovi oggetti caricati, in questo caso solamente il data frame che si chiama forbes94. Provate a ottenere informazioni sulle caratteristiche di questo oggetto con le funzioni str() e View(). Nel caso il file da aprire non fosse nel formato .RData, è necessario usare una delle utility fornite da RStudio per importare dati da altri formati. Trovate queste utility nel menu File \\(\\rightarrow\\) Import Dataset. E’ possibile importare dati in formato testo (ovvero .txt o .csv), in formato Excel (ovvero .xls o .xlsx), in formato SPSS (ovvero .sav), in formato SAS (ovvero .sas) o in formato Stata (ovvero .dta). Selezionando una di queste voci sarà aperta una finestra attraverso cui potete scegliere alcune impostazioni (come ad esempio scegliere se il file usa il punto o la virgola come separatore decimale o se la prima riga del file contiene i nomi delle variabili) e vedere un’anteprima del file che state per importare La Figura 1.17 mostra questa finestra per l’importazione del file Forbes94.xlsx. Il risultato di questa operazione sarà un data frame che conterrà i dati richiesti secondo le impostazioni scelte. Figura 1.17: Schermata di importazione di un file Excel in RStudio. Come esercizio, provate a ripetere la procedura importando il file di testo Forbes94.csv. Per salvare uno o più oggetti è disponibile la funzione save(), la quale richiede obbligatoriamente di specificare gli oggetti da salvare indicandone i nomi tra virgolette e l’argomento file che conterrà il nome del file in cui salvare gli oggetti. Il codice seguente salva gli oggetti x, txt e A creati in precedenza nel file prova.RData all’interno della directory corrente: &gt; save(&quot;x&quot;, &quot;txt&quot;, &quot;A&quot;, file = &quot;prova.RData&quot;) In Radiant è possibile caricare e salvare dei file dalla schermata Data. Per caricare un file è necessario prima scegliere il formato dello stesso nel box Load data of type e quindi cliccare sul pulsante Browse per selezionare il file. Radiant consente di caricare file in formato .RData, .rds e .csv, ma non da altri formati. Nel caso il file con estensione .RData selezionato contenga più di un oggetto, Radiant mostrerà un messaggio di errore. Per salvare il data frame attivo in Radiant, si deve prima scegliere il formato nel box Save data to type (i formati disponibili sono gli stessi visti per il caricamento) e quindi premere il pulsante Save. Questa operazione salverà il data set attivo in un file che avrà lo stesso nome del data set nella directory di lavoro corrente. Per cambiare la directory di lavoro, posizionatevi all’interno della directory nel tab Files e cliccate sull’icona con l’ingranaggio (More), e infine scegliete Set As Working Directory.↩ "],
["statistica-descrittiva.html", "Capitolo 2 Statistica descrittiva", " Capitolo 2 Statistica descrittiva In questo capitolo descriviamo alcuni strumenti per effettuare analisi descrittive su un set di dati. Come abbiamo discusso nel corso, le analisi descrittive consistono tipicamente in una o più tabelle, alcuni indici di sintesi e una serie di grafici, i quali congiuntamente sono in grado di sintetizzare le caratteristiche salienti della distribuzione empirica dei dati che stiamo analizzando. In questa sede ci limitiamo a presentare i principali strumenti discussi durante il corso, ma ovviamente R e Radiant contengono una serie di altre analisi di cui non ci occuperemo in questo manuale. Dopo aver illustrato alcuni esempi direttamente con R, passeremo a presentare alcuni strumenti disponibili in Radiant per effettuare analisi descrittive, mentre rimandiamo all’Appendice chi fosse interessato alla presentazione di ulteriori comandi di R. Nel capitolo faremo numerosi esempi usando i dati relativi al ranking effettuato dalla rivista Forbes nel 1994 degli 800 CEO americani più pagati negli Stati Uniti, data set già presentato nel capitolo precedente (vedi la Sezione 1.8). "],
["descriptive-R.html", "2.1 Primi esempi con R", " 2.1 Primi esempi con R Prima di passare a Radiant, riteniamo utile presentare alcuni comandi di R, ovvero table(), pie() e boxplot(), che consentono di svolgere delle semplici analisi descrittive. La funzione table() consente di creare una distribuzione di frequenze per una singola variabile qualitativa/categorica o numerica discreta. A titolo d’esempio, consideriamo la variabile MBA, la quale indica quali dei CEO inclusi nel data frame forbes94 possedevano un titolo di MBA nel 1994. Il codice seguente costruisce la distribuzione di frequenze della variabile MBA: &gt; table(forbes94$MBA) 0 1 589 211 L’output generato da table() è di fatto un vettore i cui elementi sono denominati con le categorie osservate di MBA. E’ possibile rappresentare graficamente una distribuzione di frequenze per una variabile categorica con un diagramma a torta, disponibile in R tramite la funzione pie(): &gt; pie(table(forbes94$MBA), main = &quot;Diagramma a torta per MBA&quot;) Figura 2.1: Esempio di diagramma a torta con R. L’argomento opzionale main, che ha valore di default &quot;&quot; (ovvero una stringa di testo vuota), serve per aggiungere un titolo al grafico. Come ultimo esempio di analisi descrittive svolte direttamente in R presentiamo la funzione boxplot(), che consente di produrre un box-plot per una singola variabile numerica. Per esempio, il box-plot della variabile Salary si ottiene come segue: &gt; boxplot(forbes94$Salary) Figura 2.2: Esempio di box-plot con R. Come tutte le funzioni che producono un output grafico, anche boxplot() contiene una lunga serie di argomenti, tra cui troviamo main, xlab e ylab, i quali servono rispettivamente per aggiungere un titolo, la descrizione dell’asse orizzontale e quella dell’asse verticale. Un argomento (logico) specifico di boxplot() è horizontal, con il quale possiamo indicare se produrre il box-plot in orizzontale (TRUE) oppure in verticale (FALSE, valore di default): &gt; boxplot(forbes94$Salary, main = &quot;Box-plot di Salary&quot;, xlab = &quot;Salary (in $)&quot;, + horizontal = TRUE) Figura 2.3: Esempio di box-plot con R. "],
["analisi-descrittive-univariate.html", "2.2 Analisi descrittive univariate", " 2.2 Analisi descrittive univariate 2.2.1 Una singola variabile categorica Nel caso ci interessi sintetizzare le informazioni relative ad una variabile categorica, gli strumenti che possiamo utilizzare sono la distribuzione di frequenze insieme ad una rappresentazione grafica della stessa28. Prima di mostrare alcuni esempi, vi ricordiamo che in R le variabili categoriche corrispondono a vettori di tipo factor, che abbiamo presentato nella Sezione 1.3.4. Se la variabile che intendete analizzare non fosse codificata come factor, dovete prima convertirla in quel formato. Una volta caricato il data set, possiamo eseguire questa operazione in Radiant posizionandoci nel tab Transform del menu Data e seguendo questa procedura: selezionate la variabile nella lista delle variabili che trovata sulla sinistra29 nel box chiamato Transformation type, scegliete Change type nel box chiamato Change variable type, scegliete As factor cliccate sul pulsante verde +Store per confermare le scelte effettuate In Figura 2.4 potete vedere la corrispondente schermata applicata alla variabile IndustryCode. Figura 2.4: Schermata Radiant per la conversione di una colonna numerica in un vettore factor. Fate attenzione perché, a meno che non modifichiate prima il nome del data frame nel box Store changes in, premendo su +Store sovrascriverete il data frame originale30. Per costruire la distribuzione di frequenze di una variabile categorica in Radiant possiamo usare la procedura seguente (si veda la Figura 2.5): cliccate sul tab Pivot del menu Data cliccate nel box Categorical variables e selezionate la variabile WideIndustry cliccate sul pulsante verde Create pivot table per generare la tabella Figura 2.5: Schermata Radiant per la costruzione di una distribuzione di frequenze di un vettore di tipo factor (ovvero di una variabile categorica). La tabella non sarà visualizzata completamente a meno che non scegliate All nel box Show ... entries che trovate sopra la tabella stessa. Potete anche salvare la tabella in un file di testo CSV se cliccate sulla freccia rivolta verso il basso che si trova in alto a destra rispetto alla tabella. Infine, potete visualizzare il diagramma a barre corrispondente alla distribuzione di frequenze31 cliccando sul checkbox Show plot. Se il numero di livelli della variabile è elevato (più di 15-20), consigliamo di rendere il grafico più leggibile cliccando sul checkbox Flip nella parte denominata Plot type. Questa opzione consente di produrre il grafico in orizzontale. Per riportare nella tabella e nel grafico le frequenze relative invece che quelle assolute, cliccate sul box Normalize by e scegliete Total. Vi facciamo notare che eventuali modifiche al contenuto della tabella richiedono l’aggiornamento del risultato, ottenibile cliccando sul pulsante verde Update pivot table. 2.2.2 Una singola variabile numerica La distribuzione di una variabile numerica è rappresentata da una tabella che riporta le frequenze con cui sono stati osservati i diversi valori, nel caso la variabile sia discreta, o le classi in cui è stata divisa, nel caso in cui la variabile sia continua. In entrambi i casi in Radiant è possibile utilizzare ancora il tab Pivot del menu Data, ma nel caso di variabili continue sarà prima necessario dividere i valori in classi32. Per rappresentare graficamente la distribuzione di una variabile numerica è possibile usare vari tipi di grafici tra cui il diagramma ad aste, l’istogramma e il box-plot. Radiant consente di produrre solo gli ultimi due, mentre il box-plot può essere costruito solo per gruppi di osservazioni corrispondenti alle categorie di una variabile categorica. In Radiant possiamo costruire un istogramma nel tab Visualize del menu Data seguendo questa procedura: scegliete Distribution nel box Plot-type selezionate la variabile nel box chiamato X-variable cliccate sul pulsante verde Create plot Lo slider denominato Number of bins ci permette di scegliere il numero di classi da usare. La Figura 2.6 riporta l’istogramma con 10 classi di uguale ampiezza per la variabile Salary. Figura 2.6: Schermata Radiant per la costruzione di un istogramma. Purtroppo Radiant non consente di costruire istogrammi con classi di diversa ampiezza, ma permette invece di generare istogrammi per sottogruppi di dati (ovvero permette di rappresentare graficamente le distribuzioni condizionate di una variabile rispetto ai valori assunti da una seconda variabile). Se ad esempio volessimo costruire gli istogrammi di Salary condizionatamente ai valori assunti dalla variabile MBA, la quale indica se ognuno dei CEO possedeva il titolo di MBA (valore 1) nel 1994 oppure no (valore 0), in aggiunta alle selezioni precedenti è necessario scegliere MBA nel box denominato Facet column e cliccare sul pulsante verde Update plot. Il risultato è mostrato in Figura 2.7. Figura 2.7: Schermata Radiant per la costruzione di un istogramma condizionatamente ai valori di una seconda variabile. Per quanto riguarda i box-plot, Radiant non dà la possibilità di costruire il box-plot per una singola variabile, ma permette di creare box-plot per sottogruppi di dati come abbiamo appena visto per gli istogrammi. L’unica differenza è che per ottenere i box-plot dobbiamo scegliere Box-plot nel box Plot-type (vedi Figura 2.8). Vi facciamo infine notare che, in presenza di outlier, Radiant costruisce i box-plot utilizzando una regola leggermente diversa rispetto a quella presentata nel corso. Per avere più dettagli sulla costruzione dei box-plot in Radiant vi invitiamo a consultare l’help, a cui si può accedere cliccando sul simbolo ? in basso a sinistra nella schermata. Figura 2.8: Schermata Radiant per la costruzione di un box-plot condizionatamente ai valori di una seconda variabile. Il calcolo degli indici di sintesi in Radiant è effettuato nel tab Explore, in cui è necessario selezionare le variabili oggetto dell’analisi nel box denominato Numeric variable(s) e la lista di indici da calcolare nel box Apply function(s). In particolare, cliccando su quest’ultimo apparirà una lista di indici disponibili tra cui scegliere. A titolo di esempio, calcoliamo il numero di dati mancanti (n_missing), la media campionaria (mean), la deviazione standard campionaria (sd), i quartili campionari (25% e 75%) e il coefficiente di variazione campionario (cv) per le variabili Salary, Bonus e Other, le quali indicano rispettivamente lo stipendio, i bonus e altre compensazioni ricevute dai CEO nel 1994. Il risultato è mostrato in Figura 2.9. Figura 2.9: Schermata Radiant per il calcolo degli indici di sintesi. Tramite il box Group by è possibile richiedere il calcolo degli indici per sottogruppi di dati, in analogia a quanto visto per l’istogramma e il box-plot. In R e Radiant non esiste una funzione per il calcolo della moda, la quale si può comunque desumere dalla distribuzione di frequenze e dal relativo grafico.↩ E’ possibile applicare questa modifica contemporaneamente a un gruppo di variabili selezionandole tutte insieme nella lista.↩ Questa operazione non sovrascrive il file .RData originale, ma solo la copia locale del data frame caricata in memoria da Radiant.↩ Radiant non dà la possibilità di creare diagramma a torta. Nella Sezione 2.1 abbiamo spiegato come produrne uno direttamente con R.↩ Si può effettuare questa operazione scegliendo il tab Transform nel menu Data, selezionando Bin nel box Transformation type e indicando il numero di classi (solo di uguale ampiezza) che si intende usare. Fate attenzione perché questa procedura richiede che non ci siano dati mancanti nella colonna da ricodificare in classi. In presenza di dati mancanti, Radiant mostrerà un messaggio di errore.↩ "],
["analisi-descrittive-bivariate.html", "2.3 Analisi descrittive bivariate", " 2.3 Analisi descrittive bivariate L’analisi congiunta di due variabili consente di verificare se esiste una qualche forma di dipendenza tra le stesse. Come per le analisi univariate, anche per quelle bivariate gli strumenti da utilizzare dipendono dal tipo di variabili coinvolte nell’analisi. 2.3.1 Due variabili categoriche Nel caso volessimo analizzare congiuntamente due variabili categoriche, lo strumento principale da utilizzare consiste nella tabella a doppia entrata. In Radiant possiamo costruire una tabella a doppia entrata spostandoci nel tab Pivot, selezionando le due variabili da analizzare nel box Categorical variables e cliccando sul pulsante verde Create pivot table. Un esempio per le variabili MBA e WideIndustry è riportato in Figura 2.10. Figura 2.10: Schermata Radiant per il calcolo di una tabella a doppia entrata. In Radiant è possibile modificare la tabella per ottenere le corrispondenti distribuzioni delle frequenze relative e le distribuzioni condizionate per riga e per colonna scegliendo rispettivamente Total, Row o Column nel box Normalize by. In Figura 2.11 riportiamo la tabella con le distribuzioni condizionate della variabile MBA dato il valore della variabile WideIndustry. Figura 2.11: Schermata Radiant per il calcolo di una distribuzione condizionata. Un modo più efficace per analizzare l’associazione tra una coppia di variabili categoriche è attraverso un diagramma a barre che confronta le distribuzioni condizionate della variabile di colonna in corrispondenza dei diversi valori della variabile di riga. In Radiant possiamo creare un diagramma a barre (affiancate o sovrapposte) cliccando sul checkbox denominato Show plot33. Questa operazione produce un diagramma a barre affiancate, mentre cliccando su Fill si ottiene un diagramma a barre sovrapposte. In Figura 2.12 riportiamo il diagramma a barre sovrapposte per la variabile MBA contro la variabile WideIndustry, dal quale possiamo concludere che esiste un certo grado di associazione tra la proporzione di CEO che possedeva un titolo di MBA nel 1994 e il settore in cui opera l’azienda. Figura 2.12: Schermata Radiant per creare un diagramma a barre sovrapposte. 2.3.2 Due variabili numeriche Nel caso in cui volessimo analizzare congiuntamente due variabili numeriche, gli strumenti che possiamo usare sono il diagramma di dispersione, la covarianza campionaria e l’indice di correlazione campionaria tra le due variabili. In Radiant è possibile effettuare queste analisi con il menu Basics \\(\\rightarrow\\) Correlation. In questa schermata è sufficiente selezionare le variabili da analizzare e cliccare sul checkbox Show covariance matrix. Il tab Plot dello stesso menu riporta il diagramma di dispersione per ognuna delle coppie di variabili. Nelle Figure 2.13 e 2.14 riportiamo le schermate di Radiant per le variabili Age, Salary, Bonus e Other. Figura 2.13: Schermata Radiant per calcolare le covarianze e le correlazioni campionarie per un inseme di variabili. Figura 2.14: Schermata Radiant per creare i diagramma di dispersione per un inseme di variabili. Fate attenzione al fatto che per ottenere un diagramma a barre che si possa interpretare come abbiamo discusso nel corso, in Radiant è necessario scambiare l’ordine delle variabili.↩ "],
["calcolo-delle-probabilita.html", "Capitolo 3 Calcolo delle probabilità", " Capitolo 3 Calcolo delle probabilità Questo capitolo è dedicato ad illustrare alcuni strumenti per il calcolo delle probabilità disponibili in Radiant. In particolare, presenteremo i comandi presenti nel menu Basics \\(\\rightarrow\\) Probability calculator, scegliendo il quale si ottiene la schermata mostrata in Figura 3.1. Figura 3.1: Schermata Radiant per il calcolo delle probabilità. Questo menu consente di effettuare calcoli probabilistici utilizzando una delle distribuzioni di probabilità elencate nel box Distribution, delle quali presenteremo i dettagli solamente per quelle discusse durante il corso, ovvero: la distribuzione binomiale (e quindi anche bernoulliana) la distribuzione normale (o gaussiana) la distribuzione \\(t\\) di Student la distribuzione \\(\\chi^2\\) (chi-quadrato) la distribuzione \\(F\\) di Fisher Per ognuna di queste distribuzioni, cliccando su Input type $\\rightarrow$ Values, Radiant permette di calcolare la probabilità che la corrispondente variabile aleatoria si trovi nell’intervallo specificato nei box Lower bound e Upper bound. In alternativa, scegliendo Input type $\\rightarrow$ Probabilities è possibile recuperare i valori della variabile aleatoria corrispondenti alle probabilità inserite nei box Lower bound e Upper bound. "],
["variabili-aleatorie-binomiali.html", "3.1 Variabili aleatorie binomiali", " 3.1 Variabili aleatorie binomiali Per effettuare calcoli probabilistici con una variabile aleatoria binomiale, selezionate nel box Distribution la voce Binomial. La schermata che vi si presenterà è riportata in Figura 3.2. Figura 3.2: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria binomiale. La schermata riporta i valori dei parametri della distribuzione, ovvero il numero di prove bernoulliane n e la probabilità di successo p in ognuna delle prove, e il corrispondente grafico della funzione di probabilità con le barre colorate in funzione dei valori riportati nei box Lower bound e Upper bound. Nella parte centrale della schermata sono riportati i valori della media e delle deviazione standard e le probabilità relative ad alcuni intervalli determinati sempre tramite i box Lower bound e Upper bound. Supponiamo di voler calcolare la probabilità con cui una variabile aleatoria binomiale di parametri \\(n = 8\\) e \\(p = 0.3\\) assuma un valore compreso nell’intervallo \\([4, 7)\\) (l’intervallo è aperto solo a destra). In questo caso dobbiamo: inserire i valori dei parametri nei box n e p se non è già selezionato, cliccare su Input type $\\rightarrow$ Values nei box Lower bound e Upper bound inserire rispettivamente 4 e 7 suggeriamo anche di aumentare a 4 il numero di cifre decimali mostrate (Decimals) La schermata che ne risulta è riportata in Figura 3.3. Figura 3.3: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria binomiale. La probabilità che ci interessa, ovvero \\(P(4 \\le X &lt; 7)\\) in cui il valore 7 è escluso, non è riportata nella tabella, la quale riporta invece \\(P(4 \\le X \\le 7)\\), in cui invece il valore 7 è incluso. La questione è facilmente risolta, perché la stessa tabella indica anche quanto vale \\(P(X = 7)\\), che quindi basta sottrarre da \\(P(4 \\le X \\le 7)\\) per ottenere il risultato cercato, ovvero \\[\\begin{equation*} P(4 \\le X &lt; 7) = P(4 \\le X \\le 7) - P(X = 7) = 0.1940 - 0.0012 = 0.1928. \\end{equation*}\\] In modo equivalente, è possibile ottenere lo stesso risultato inserendo direttamente i valori 4 e 6 nei box Lower bound e Upper bound. Rimane inteso che questa stessa schermata può essere utilizzata anche per variabili aleatorie bernoulliane semplicemente fissando ad 1 il numero di prove n. "],
["variabili-aleatorie-normali-o-gaussiane.html", "3.2 Variabili aleatorie normali (o gaussiane)", " 3.2 Variabili aleatorie normali (o gaussiane) Scegliendo Normal nel box Distribution visualizziamo la schermata per il calcolo di probabilità relative a una variabile aleatoria normale (vedi Figura 3.4), la quale di fatto rappresenta una versione elettronica e più generale della tavola della normale standard presentata nel corso. Figura 3.4: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria normale. Nel caso ci interessi calcolare una probabilità relativa ad un intervallo di valori, dobbiamo cliccare su Input type $\\rightarrow$ Values, mentre se ci interessasse la situazione opposta, ovvero il calcolo degli estremi dell’intervallo corrispondente ad un certo valore di probabilità, dobbiamo scegliere Input type $\\rightarrow$ Probabilities. Vediamo un esempio per ciascuno di questi casi. Supponiamo di voler calcolare la probabilità che una variabile aleatoria \\(X\\) distribuita secondo una normale con media 50 e varianza 64, ovvero \\(X \\sim N(\\mu = 50, \\sigma^2 = 64)\\), assuma valori nell’intervallo \\((45, 60)\\). In questo caso dobbiamo: inserire i valori dei parametri nei box Mean e St. dev.34 se non è già selezionato, cliccare su Input type $\\rightarrow$ Values nei box Lower bound e Upper bound inserire rispettivamente 45 e 60 suggeriamo anche di aumentare a 4 il numero di cifre decimali mostrate (Decimals) La schermata che ne risulta è riportata in Figura 3.5. Figura 3.5: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria normale. Il risultato cercato è riportato come P(45 &lt; X &lt; 60) = 0.6284. Vi facciamo notare che se lasciate vuoto uno dei box Lower bound o Upper bound, ciò viene interpretato da Radiant come un intervallo illimitato a sinistra o a destra35. Se invece volessimo ricavare la probabilità corrispondente ad un dato intervallo di valori, dobbiamo selezionare Input type $\\rightarrow$ Probabilities. Ad esempio, continuando con l’esempio precedente, supponiamo ci interessi ottenere il valore \\(x\\) della variabile aleatoria \\(X\\) che non sarà superato con probabilità pari a 95%, ovvero il valore \\(x\\) tale che \\(P(X \\le x) = 0.95\\). In questo caso dobbiamo: controllare che i valori dei parametri nei box Mean e St. dev. siano quelli corretti se non è già selezionato, cliccare su Input type $\\rightarrow$ Probabilities nel box Upper bound inserire il valore 0.95 e indifferentemente lasciare vuoto o inserire il valore 0 nel box Lower bound verificare di aver indicato 4 cifre decimali nel box Decimals La schermata che ne risulta è riportata in Figura 3.6. Figura 3.6: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria normale. Il risultato cercato è riportato come P(X &lt; 63.1588) = 0.95, ovvero \\(x = 63.1588\\). Attenzione, Radiant richiede di inserire il valore della deviazione standard e non della varianza. Nel nostro caso \\(\\sigma = \\sqrt{64} = 8\\).↩ In R, e quindi anche in Radiant, un valore infinito viene indicato come Inf.↩ "],
["altre-variabili-aleatorie.html", "3.3 Altre variabili aleatorie", " 3.3 Altre variabili aleatorie I dettagli per le altre variabili aleatorie presentate nel corso (ovvero \\(t\\), \\(\\chi^2\\) e \\(F\\)) sono analoghi a quanto descritto sopra per la distribuzione normale, salvo che queste distribuzioni sono definite da un set di parametri diversi. Nelle Figure 3.7, 3.8 e 3.9 riportiamo le rispettive schermate. Figura 3.7: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria \\(t\\). Figura 3.8: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria \\(\\chi^2\\). Figura 3.9: Schermata Radiant per il calcolo di probabilità relative a una variabile aleatoria \\(F\\). "],
["statistica-inferenziale.html", "Capitolo 4 Statistica inferenziale", " Capitolo 4 Statistica inferenziale In questo capitolo mostriamo come applicare le analisi inferenziali presentate nel corso. Partiremo dal caso più semplice di inferenza su una media per una popolazione normale per poi passare ai casi più complessi, inclusi il test sulla bontà di adattamento di una distribuzione con probabilità completamente specificate e il test di indipendenza in una tabella a doppia entrata. Nel capitolo presentiamo gli strumenti disponibili in Radiant, mentre rimandiamo all’Appendice per un approfondimento su alcune funzioni di R. "],
["inferenza-sulla-media-di-una-popolazione-normale.html", "4.1 Inferenza sulla media di una popolazione normale", " 4.1 Inferenza sulla media di una popolazione normale E’ possibile fare inferenza su una media \\(\\mu\\) di una popolazione normale assumendo che la varianza \\(\\sigma^2\\) della popolazione sia nota oppure no. In questa sezione ci occupiamo solo del secondo caso perché si tratta della situazione più frequente e rilevante nella pratica dell’analisi dei dati. Inoltre, né R né Radiant mettono a disposizione comandi che consentono di ottenere rapidamente i risultati nel caso in cui la varianza fosse nota. Per il caso di una singola media per una popolazione normale, Radiant include il menu Basics \\(\\rightarrow\\) Single mean. Vediamo subito un esempio usando ancora una volta i dati contenuti nel data frame forbes94. In particolare, definiamo una nuova variabile che chiamiamo ROS, ovvero return on sales, calcolata come il rapporto percentuale dei profitti rispetto ai ricavi di vendita, che esprime la redditività aziendale in relazione alla capacità remunerativa del flusso dei ricavi. Per creare la nuova variabile ROS in Radiant dovete selezionare il tab Transform del menu Data, quindi selezionare la voce Create nel box Transformation type, definire la nuova variabile digitando ROS = Profits/Sales*100 nel box Create, premere INVIO ed infine cliccare sul pulsante verde +Store per aggiungere la variabile al data frame. La schermata per l’inferenza sulla media di una popolazione normale, di cui mostriamo in Figura 4.1 un esempio per la variabile ROS, richiede di: selezionare la variabile da analizzare nel box Variable (select one) scegliere il tipo di ipotesi alternativa da testare nel box Alternative hypothesis; i valori possibili sono Two sided, Less than e Greater than scegliere il livello di confidenza con lo slider Confidence level infine, indicare il valore da testare sotto l’ipotesi nulla nel box Comparison value Radiant calcola automaticamente sia l’intervallo di confidenza sia il test sulla media. Nell’esempio relativo a ROS il test che eseguiamo è \\[\\begin{equation*} H_0: \\mu = 0 \\qquad \\mbox{vs.} \\qquad H_1: \\mu \\ne 0, \\end{equation*}\\] dove \\(\\mu\\) indica la media non nota della variabile ROS nella popolazione. Figura 4.1: Schermata Radiant per l’inferenza sulla media di una popolazione normale. I risultati indicano che l’intervallo di confidenza al 90% per \\(\\mu\\) è pari a \\((6.7799, 7.7978)\\), mentre il test restituisce un p-value molto piccolo, riportato come &lt; 0.001, il quale permette di rifiutare ampiamente l’ipotesi nulla anche decidendo di usare un livello di significatività \\(\\alpha\\) di 0.01. Nel caso si scegliesse un test unilaterale, l’intervallo di confidenza restituito da Radiant non è quello standard (ovvero bilaterale) illustrato nel corso e quindi non sarà qui commentato. "],
["inferenza-sulla-proporzione-di-successi-in-una-popolazione-bernoulliana.html", "4.2 Inferenza sulla proporzione di successi in una popolazione bernoulliana", " 4.2 Inferenza sulla proporzione di successi in una popolazione bernoulliana In analogia a quanto visto per la media di una popolazione normale, Radiant mette a disposizione il menu Basics \\(\\rightarrow\\) Single proportion per l’inferenza sulla proporzione di successi in una popolazione bernoulliana. Nella corrispondente schermata è necessario: selezionare la variabile da analizzare nel box Variable (select one) indicare la categoria che indica il “successo” nel box Choose level scegliere il tipo di ipotesi alternativa da testare nel box Alternative hypothesis; i valori possibili sono Two sided, Less than e Greater than scegliere il livello di confidenza con lo slider Confidence level infine, indicare il valore da testare sotto l’ipotesi nulla nel box Comparison value Anche in questo caso, Radiant calcola automaticamente sia l’intervallo di confidenza sia il test sulla proporzione. Supponiamo di voler stimare la proporzione di CEO con il titolo di MBA nella popolazione di riferimento usando il campione disponibile nel data frame forbes94. In aggiunta, vogliamo anche calcolarne l’intervallo di confidenza al 99% e ci interessa testare l’ipotesi nulla che la proporzione di CEO in possesso del titolo di MBA nella popolazione sia uguale al 30%. I risultati, riportati in Figura 4.2, indicano che l’intervallo di confidenza al 99% è pari a \\((0.2257, 0.3057)\\), mentre il p-value del test, pari a 0.027, ci suggerisce che esiste sufficiente evidenza empirica proveniente dai dati per rifiutare l’ipotesi nulla \\(H_0: p = 0.30\\) ad un livello di significatività \\(\\alpha\\) di 0.05, ma non di 0.0136. Figura 4.2: Schermata Radiant per il test su una singola proporzione. Questi valori non corrispondono esattamente al calcolo che abbiamo presentato nel corso, perché Radiant usa una formula leggermente diversa, ma più precisa. Ricordatevi infatti che le espressioni che abbiamo visto in questo caso sono delle approssimazioni basate sulla distribuzione asintotica normale, mentre Radiant usa quello che viene chiamato un test esatto (binomial exact), che quindi si può utilizzare anche con ampiezze campionarie piccole.↩ "],
["inferenza-sul-confronto-tra-le-medie-di-due-popolazioni-normali.html", "4.3 Inferenza sul confronto tra le medie di due popolazioni normali", " 4.3 Inferenza sul confronto tra le medie di due popolazioni normali Il caso della differenza tra due medie è uno di quelli più utilizzati nelle applicazioni e nel corso ne sono state presentate alcune varianti, in particolare: confronto tra le medie di due popolazioni normali con varianze note, campioni indipendenti confronto tra le medie di due popolazioni normali con varianze non note ma assunte uguali, campioni indipendenti confronto tra le medie di due popolazioni normali con varianze non note, campioni dipendenti In Radiant non sono disponibili strumenti per il primo caso, che quindi non presenteremo qui, mentre per il secondo offre solo la possibilità di confrontare due medie nel caso in cui le varianze siano non note e diverse. Questa situazione non è stata presentata nel corso perché i calcoli richiesti sono impegnativi, ma dal momento che ora sarà Radiant a fare i conti, ne discuteremo comunque l’applicazione. 4.3.1 Campioni indipendenti Per confrontare le medie di due popolazioni normali con varianze non note in Radiant possiamo utilizzare il menu Basics \\(\\rightarrow\\) Compare means, ma rispetto al caso di una singola media dovremo ora fornire i seguenti input: nel box Select a factor or numeric variable dobbiamo indicare la variabile (tipicamente di tipo factor) che identifica i gruppi di cui vogliamo confrontare le medie nel successivo box Numeric variable dobbiamo selezionare la variabile numerica di cui vogliamo confrontare le medie nel box Alternative hypothesis indichiamo il tipo di ipotesi alternativa che vogliamo testare; i valori possibili sono Two sided per il test bilaterale e Less than o Greater than per i test unilaterali lo slider Confidence level ci permette di scegliere il livello di confidenza il checkbox Show additional statistics permette di visualizzare altri risultati (ad esempio gli intervalli di confidenza, che quindi non sono proposti in automatico) dobbiamo verificare che sia selezionato il pulsante independent nella sezione Sample type dobbiamo infine verificare che sia selezionato il pulsante t-test nella sezione Test type Vediamo subito un esempio in cui confrontiamo la media della variabile ROS nei due gruppi identificati dalla variabile MasterPhd, che indica i CEO che nel 1994 possedevano un titolo di Master o di PhD. Calcoliamo l’intervallo di confidenza al 95% e effettuiamo il test per verificare se le medie delle rispettive popolazioni siano uguali, ovvero \\[\\begin{equation*} H_0: \\mu_{(\\mbox{MasterPhd}=0)} = \\mu_{(\\mbox{MasterPhd}=1)} \\quad \\mbox{vs.} \\quad H_1: \\mu_{(\\mbox{MasterPhd}=0)} \\ne \\mu_{(\\mbox{MasterPhd}=1)}. \\end{equation*}\\] I risultati sono riportati in Figura 4.3. Figura 4.3: Schermata Radiant per il test sul confronto tra due medie (campioni indipendenti). La media campionaria nel secondo campione (MasterPhd = 1) risulta essere maggiore che nel primo (MasterPhd = 0) e i risultati del test suggeriscono che sembrano esserci differenze significative tra le medie del ROS nelle due popolazioni di aziende, quelle il cui CEO non ha un Master o un Phd e quelle in cui il CEO ha un Master o un Phd, ma solo se decidiamo di usare un livello di significatività del 10% (il p-value del test risulta infatti pari a 0.0837). Il tab Plot dello stesso menu consente di visualizzare i risultati in forma grafica attravero diversi tipi di grafici (Scatter, Box, Density, Bar). La Figura 4.4 mostra alcuni di questi grafici per l’esempio precedente. Figura 4.4: Schermata Radiant per il test sul confronto tra due medie (campioni indipendenti). 4.3.2 Campioni dipendenti Un’ulteriore situazione che si può incontrare in pratica è quella in cui le medie da confrontare riguardano la stessa popolazione che però è stata osservata in due momenti o, più in generale, sotto due condizioni diverse. Questo è il caso di campioni dipendenti, poiché in tale contesto il medesimo campione viene osservato due volte. Nello stesso ambito è compreso anche il caso in cui i due campioni, pur essendo diversi, sono stati “appaiati” in modo da approssimare il più precisamente possibile la situazione di un singolo campione osservato ripetutamente. In entrambi i contesti (stesso campione osservato due volte o due campioni appaiati), i campioni devono contenere lo stesso numero di osservazioni. Anche questo caso può essere gestito in Radiant attraverso il comando Basics \\(\\rightarrow\\) Compare means descritto nella sezione precedente, salvo che ora dovremo selezionare il checkbox denominato paired. Vediamo un esempio usando i dati contenuti nel data frame supermarket nell’omonimo file. Il data frame contiene il numero di clienti che hanno visitato un campione di 10 negozi di una catena di supermercati in due giorni diversi, in uno solo dei quali era attiva una promozione. In particolare, il data frame contiene le seguenti variabili: store, che indica il negozio a cui l’osservazione si riferisce customers, che indica il numero di clienti che hanno visitato ognuno dei negozi nei due giorni program, che indica invece il giorno in cui la promozione era attiva L’obiettivo di questo esempio è valutare se la promozione sia stata efficace in termini di aumento del numero medio di clienti che hanno visitato i negozi. Calcoleremo sia l’intervallo di confidenza al 90% sia il seguente test \\[\\begin{equation*} H_0: \\mu_X - \\mu_Y \\ge 0 \\qquad \\mbox{vs.} \\qquad H_1: \\mu_X - \\mu_Y &lt; 0, \\end{equation*}\\] dove \\(X\\) indica la popolazione di negozi in cui la promozione non è attiva, mentre \\(Y\\) denota la popolazione di negozi in cui la promozione è attiva. Dopo aver caricato i dati e scelto il comando Basics \\(\\rightarrow\\) Compare means: nel box Select a factor or numeric variable scegliamo program come variabile che identifica i due campioni nel successivo box Numeric variable selezionamo la variabile numerica customers nel box Alternative hypothesis indichiamo il tipo di ipotesi alternativa che vogliamo testare; in particolare in questo esempio scegliamo Less than perché ci interessa verificare se i dati suggeriscono che la promozione ha permesso di aumentare il numero medio di visite ai negozi lo slider Confidence level ci permette di indicare il livello di confidenza che ci interessa usare il checkbox Show additional statistics permette di visualizzare ulteriori risultati dobbiamo verificare che sia selezionato il pulsante paired nella sezione Sample type dobbiamo infine verificare che sia selezionato il pulsante t-test nella sezione Test type La Figura 4.5 mostra i risultati dell’analisi: Figura 4.5: Schermata Radiant per il test sul confronto tra due medie (campioni dipendenti). I risultati indicano che, assumendo di usare un livello di significatività del 5%, la promozione sembra avere avuto un effetto significativo sulla media del numero di visite poiché il p-value del test (0.033) è inferiore a 0.05. Concludiamo questa sezione evidenziando che in questi risultati l’intervallo di confidenza che viene restituito da Radiant è quello unilaterale, che non consideriamo in questo manuale. Ricordiamo che Radiant include solo il caso di varianza non note e diverse.↩ "],
["inferenza-sullindice-di-correlazione-lineare.html", "4.4 Inferenza sull’indice di correlazione lineare", " 4.4 Inferenza sull’indice di correlazione lineare L’indice di correlazione lineare costituisce lo strumento principale per valutare l’intensità dell’associazione lineare tra due variabili numeriche. Abbiamo già discusso come effettuare un’analisi di correlazione in Radiant attraverso il comando Basics \\(\\rightarrow\\) Correlation. Le Figure 2.13 e 2.14 riportate in Sezione 2.3.2 riportano i risultati dell’esempio relativo alle variabili Age, Salary, Bonus e Other. Tali risultati mostrano ad esempio che l’indice di correlazione campionario tra le variabili Age e Salary, pari a 0.24, segnala un’associazione lineare debole, ma il basso valore del p-value evidenzia che tale associazione è altamente significativa. "],
["test-sulla-bonta-di-adattamento-probabilita-completamente-specificate.html", "4.5 Test sulla bontà di adattamento (probabilità completamente specificate)", " 4.5 Test sulla bontà di adattamento (probabilità completamente specificate) Il test sulla bontà di adattamento consente di valutare se una distribuzione di probabilità osservata per una variabile aleatoria discreta (con supporto finito) possa essere considerata “compatibile” con una distribuzione di probabilità teorica definita a priori. Radiant consente di effettuare tale test con il comando Basics \\(\\rightarrow\\) Goodness of fit. Nella schermata che appare, è necessario inserire le seguenti informazioni: la variabile nel data set che contiene i dati con cui effettuare l’analisi (box Select a categorical variable) le probabilità che definiscono la distribuzione teorica con cui confrontare quella osservata (box Probabilities); queste probabilità devono essere inserite come numeri compresi tra 0 e 1, la cui somma deve essere pari a 1 e il cui numero deve essere pari alle categorie osservate per la variabile indicata nel box precedente il tipo di output da mostrare (box Observed per le frequenze osservate, Expected per quelle attese sotto l’ipotesi nulla, Chi-squared per il contributo al calcolo dell’indice \\(\\chi^2\\) di ogni categoria38) Consideriamo ancora una volta il data frame forbes94 e in particolare la variabile MasterPhd. Proviamo a testare l’ipotesi nulla che nella popolazione da cui questi CEO provengono la quota percentuale di essi con e senza un Master o un PhD sia la stessa, ovvero 50% e 50%. La Figura 4.6 mostra le selezioni da effettuare e l’output corrispondente. Figura 4.6: Schermata Radiant per il test sulla bontà di adattamento. L’output riporta un p-value pari a 0.777, ovvero i dati non consentono di scartare l’ipotesi nulla e quindi non si hanno sufficienti prove a sfavore dell’affermazione che la quota percentuale di CEO con un Master o un PhD sia diversa dal 50%39. Vediamo ora un secondo esempio: il file market_share.RData contiene l’omonimo data frame, il quale include un’unica variabile chiamata Brand. Questa colonna raccoglie il brand di un certo prodotto acquistato da 400 clienti di un grossista. Tali dati sono relativi a clienti posti in una nuova zona di vendita. Il grossista vuole valutare se la politica di magazzino dei 4 brand che ha utilizzato nella sua zona storica di vendita possa essere replicata anche nella nuova zona. Per fare ciò, il grossista desidera confrontare la distribuzione osservata per il campione di 400 clienti dalla nuova zona con le preferenze dei clienti della zona storica, ovvero 20% per il brand A, 35% per il brand B, 30% per il brand C e 15% per il brand D. La distribuzione di frequenze dei brand acquistati dai clienti inclusi nel campione è riportata in Figura 4.7. Figura 4.7: Distribuzione di frequenze dei brand acquistati dai clienti inclusi nel data frame market_share. Dopo aver selezionato la variabile Brand nel box Select a categorical variable e inserito i valori .2 .35 .3 .15 nel box Probabilities, è possibile visualizzare vari risultati relativi al test sulla bontà di adattamento (si veda Figura 4.8). Figura 4.8: Schermata Radiant per il test sulla bontà di adattamento. Adottando un livello di significatività del 5% possiamo concludere che i dati (p-value = \\(0.032 &lt; 0.05\\)) supportano la conclusione che la distribuzione delle preferenze nella nuova zona non sia compatibile con quelle della zona storica e che quindi non sia possibile replicare la stessa politica di magazzino. Concludiamo questa sezione facendovi notare che Radiant riporta sempre nell’output di questo test una valutazione delle ipotesi su cui è basato il test. Per l’esempio precedente, infatti, riporta che 0.0 \\% of cells have expected values below 5, quindi l’approssimazione sulla base della quale il p-value è calcolato si può ritenere accettabile. La schermata consente anche di visualizzare altri risultati, indicati come Deviation std., che non sono stati illustrati nel corso e che quindi non discuteremo neppure in questa sede.↩ Notate che il p-value ottenuto è di fatto uguale a quello che otterremo con un test su una singola proporzione, perché in questo caso la variabile che stiamo considerando assume solo due categorie.↩ "],
["test-di-indipendenza-in-una-tabella-a-doppia-entrata.html", "4.6 Test di indipendenza in una tabella a doppia entrata", " 4.6 Test di indipendenza in una tabella a doppia entrata Nella sezione conclusiva di questo capitolo presentiamo un ultimo test che in un certo senso estende il test di adattamento presentato nella sezione precedente al caso di un vettore di due variabili aleatorie discrete, anche se la distribuzione teorica con cui quella empirica viene confrontata è relativa ad una situazione particolare, quella di indipendenza statistica delle due variabili (ipotesi nulla). Radiant permette di effettuare il test di indipendenza in una tabella a doppia entrata attraverso il comando Basics \\(\\rightarrow\\) Cross-tabs. Le informazioni che dobbiamo fornire nella relativa schermata sono: il nome delle variabili che contengono i dati su cui vogliamo effettuare il test di indipendenza (due box successivi, entrambi denominati Select a categorical variable; consigliamo di selezionare la variabile di riga nel primo box e quella di colonna nel secondo) il tipo di output da mostrare, ovvero le frequenze osservate (Observed), quelle attese sotto l’ipotesi nulla di indipendenza (Expected), i contributi al calcolo dell’indice \\(\\chi^2\\) di ogni cella della tabella (Chi-squared), le radici quadrate dei medesimi contributi (Deviation std.), le frequenze condizionate date le righe, quelle condizionate date le colonne o quelle congiunte relative (rispettivamente Row percentages, Column percentages e Table percentages). Le Figure 4.9 e 4.10 riportano l’output relativo al test di indipendenza tra le variabili MasterPhd e WideIndustry. Figura 4.9: Schermata Radiant per il test di indipendenza (frequenze osservate). Figura 4.10: Schermata Radiant per il test di indipendenza (frequenze attese). Il p-value del test riportato nell’output (&lt; .001) permette di concludere che sembra esserci sufficiente evidenza empirica a sfavore dell’ipotesi di indipendenza tra le due variabili. In altre parole, possiamo concludere che la proporzione di CEO con un Master o un PhD dipenda in qualche modo dal settore in cui l’azienda opera (per averne conferma, provate a dare un’occhiata alle frequenze condizionate date le righe). Anche per il test di indipendenza Radiant riporta nell’output una valutazione delle ipotesi su cui è basato il test. Per l’esempio precedente, infatti, riporta che 0.0 \\% of cells have expected values below 5, quindi l’approssimazione sulla base della quale il p-value è calcolato si può ritenere accettabile. Una piccola nota tecnica sul p-value riportato in output: quando una o più delle frequenze attese sono piccole, ovvero pari a 5 o meno, Radiant procede al calcolo del p-value usando un metodo di simulazione. Questi casi sono segnalati nell’output attraverso la frase p.value for chi-squared statistics obtained using simulation (2,000 replicates). Questo valore del p-value non corrisponde a quello che otterremmo con la distribuzione chi-quadrato, ma normalmente non dovrebbe discostarsi di molto. "],
["chapter5.html", "Capitolo 5 Il modello di regressione lineare", " Capitolo 5 Il modello di regressione lineare In questo capitolo presentiamo uno degli argomenti del corso in assoluto più importanti da un punto di vista applicativo, ovvero il modello di regressione lineare. Inizieremo illustrando come stimare un modello semplice, ovvero con un solo regressore, per poi procedere con il più generale modello multiplo, che invece può includere un numero qualsiasi di regressori. Successivamente mostreremo come calcolare le previsioni a partire da un modello stimato, per poi concludere con la valutazione della presenza di osservazioni particolarmente influenti. In questo capitolo useremo solo il codice R sia perché Radiant fornisce degli strumenti troppo limitati rispetto a quello che ci interessa discutere su questo importante argomento, sia perché questo codice rappresenta il punto di partenza per analisi più complesse che potranno essere utili in altri corsi futuri. "],
["simple-reg.html", "5.1 Il modello di regressione lineare semplice", " 5.1 Il modello di regressione lineare semplice Come sappiamo, il modello di regressione lineare semplice è definito come \\[\\begin{equation} Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i, \\quad i=1,\\ldots,n, \\tag{5.1} \\end{equation}\\] dove \\((x_i, y_i)\\) rappresentano le coppie di osservazioni facenti parte del campione, \\(\\beta_0\\) e \\(\\beta_1\\) sono i coefficienti non noti che si suppone leghino le variabili \\(X\\) e \\(Y\\) nella popolazione, mentre \\(\\varepsilon_i\\) corrisponde all’errore casuale che intuitivamente descrive l’informazione relativa a \\(Y\\) che non è possibile spiegare attraverso una funzione lineare di \\(X\\). In aggiunta all’equazione (5.1), il modello di regressione lineare semplice è definito anche dalle seguenti ipotesi: le osservazioni \\(x_i\\) sono costanti o realizzazioni di una variabile aleatoria \\(X\\) non correlata con le componenti aleatorie di errore, \\(\\varepsilon_i\\). In quest’ultimo caso l’inferenza è svolta condizionatamente ai valori osservati di \\(X\\) gli errori aleatori, \\(\\varepsilon_i\\), sono variabili aleatorie con media 0 e varianza \\(\\sigma^2\\) costante per ogni \\(i = 1,\\ldots,n\\) (omoschedasticità) gli errori aleatori, \\(\\varepsilon_i\\), non sono correlati tra loro gli errori aleatori, \\(\\varepsilon_i\\), sono distribuiti secondo una distribuzione normale La funzione principale per stimare un modello di regressione lineare in R è lm(), che sta per linear model. Il primo argomento di questa funzione è un tipo di oggetto che non abbiamo mai usato finora chiamato formula. Gli oggetti di tipo formula sono impiegati in R per specificare una relazione tra una variabile dipendente y e una (o più) variabili indipendenti x. Per specificare un oggetto di tipo formula è necessario utilizzare un simbolo particolare che non è sempre facile recuperare sulle tastiere italiane, ovvero il simbolo di tilde “~”40. La particolare combinazione di tasti che è necessario usare per ottenere tale simbolo dipende dal sistema operativo (Mac, Windows, ecc.), dal tipo di macchina che state usando (laptop, desktop, ecc.), oltre che dal particolare brand della vostra macchina. Per questo motivo, non è possibile indicare qui in modo univoco come ottenere la tilde sul vostro particolare computer, ma vi suggeriamo un modo poco elegante, ma molto semplice, per recuperarlo: eseguite il codice ?tilde, copiate il carattere di tilde che trovate nella pagina di help e incollatelo dove vi serve41. La sintassi generale della funzione lm() è lm(y ~ x), la quale restituisce una lista (si veda la Sezione 1.3.6) contenente un gran numero di risultati relativi alla stima del modello considerato. A titolo d’esempio, consideriamo il data frame comp disponibile nel file competitors.RData. Il data frame comp contiene i valori rilevati in 113 settimane successive per le seguenti variabili relative a un’azienda che produce un prodotto destinato al consumo alimentare: mktshare indica la quota di mercato (in termini relativi) dell’azienda rilevata alla fine di ogni settimana ownprice indica il prezzo (in $) alla fine di ogni settimana del prodotto offerto dall’azienda in questione comp1price indica il prezzo (in $) alla fine di ogni settimana del medesimo prodotto offerto da un competitor dell’azienda comp2price indica il prezzo (in $) alla fine di ogni settimana del medesimo prodotto offerto da un secondo competitor dell’azienda Vogliamo stimare la relazione lineare che intercorre tra la quota di mercato dell’azienda nelle varie settimane e il prezzo del proprio prodotto nelle medesime settimane, ovvero ci interessa stimare il modello \\[\\begin{equation} \\mbox{mktshare}_i = \\beta_0 + \\beta_1 \\mbox{ownprice}_i + \\varepsilon_i. \\tag{5.2} \\end{equation}\\] Dopo aver caricato il file dei dati (vedi la Sezione 1.8), si può utilizzare la funzione View() per vederli. Il codice seguente utilizza la funzione lm() per stimare il modello, i cui risultati sono memorizzati nell’oggetto comp_m1, di cui si può ottenere una sintesi attraverso la funzione summary(): &gt; load(&quot;competitors.RData&quot;) &gt; comp_m1 &lt;- lm(mktshare ~ ownprice, data = comp) &gt; summary(comp_m1) Call: lm(formula = mktshare ~ ownprice, data = comp) Residuals: Min 1Q Median 3Q Max -0.01715 -0.00961 -0.00310 0.00642 0.05011 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.11043 0.01498 7.37 3.2e-11 *** ownprice -0.04532 0.00896 -5.06 1.7e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.0129 on 111 degrees of freedom Multiple R-squared: 0.187, Adjusted R-squared: 0.18 F-statistic: 25.6 on 1 and 111 DF, p-value: 1.67e-06 Vi facciamo notare che oltre all’argomento di tipo formula mktshare ~ ownprice, che specifica il modello da stimare, nella funzione lm() abbiamo aggiunto anche un secondo argomento, denominato data. Questo argomento serve per indicare ad R il data frame in cui si trovano le variabili specificate nella formula42. La funzione summary(), applicata alla lista restituita dalla funzione lm(), produce un output che consiste delle seguenti parti: la prima riga dell’output (Call) riporta il codice che è stato eseguito la seconda parte dell’output (Residuals) offre una sintesi dei residui del modello la terza parte (Coefficients) fornisce le stime dei coefficienti del modello insieme ai relativi p-value. Per l’esempio precedente, il modello stimato è quindi dato da \\[\\begin{equation} \\widehat{\\mbox{mktshare}}_i = 0.1104 -0.0453 \\, \\mbox{ownprice}_i. \\tag{5.3} \\end{equation}\\] la quarta e ultima parte (ultime tre righe) contiene alcuni indici utili per valutare la bontà complessiva del modello, in particolare la stima di \\(\\sigma\\) (indicata come Residual standard error), l’indice \\(R^2\\) (riportato come Multiple R-squared), e il test \\(F\\) (ultima riga dell’output) L’indice \\(R^2\\) (0.1874) indica una limitata capacità predittiva del modello, anche se il basso p-value del coefficiente \\(\\beta_1\\) (1.67e-06) segnala che l’associazione lineare tra le due variabili è significativa da un punto di vista statistico. E’ possibile visualizzare la retta stimata direttamente sul diagramma di dispersione delle due variabili attraverso il seguente codice43: &gt; plot(mktshare ~ ownprice, data = comp) &gt; abline(comp_m1, lwd = 2, col = &quot;blue&quot;) Figura 5.1: Diagramma di dispersione di mktshare contro ownprice e relativa retta stimata. La prima linea di codice usa la funzione plot(), ma a differenza di quanto abbiamo visto in precedenza, in questo caso abbiamo indicato le variabili da rappresentare nel grafico attraverso una formula. La seconda linea di codice utilizza invece la funzione abline(), la quale aggiunge al grafico attivo una linea, in questo caso la retta stimata. L’output fornito da R per un modello di regressione lineare include i p-value per i test sui due coefficienti, ma non include i rispettivi intervalli di confidenza. Per ottenere questi ultimi è necessario utilizzare la funzione confint() direttamente sul risultato di lm(). Per il precedente esempio otteniamo: &gt; confint(comp_m1) 2.5 % 97.5 % (Intercept) 0.08074 0.14012 ownprice -0.06307 -0.02757 Altre funzioni utili per esaminare i risultati della stima di un modello di regressione lineare (non solo semplice) sono: coef(), che stampa le stime dei coefficienti residuals(), che calcola i residui del modello fitted(), che calcola i valori previsti dal modello per le sole osservazioni incluse nel campione anova(), che produce la scomposizione della devianza predict(), che consente di calcolare le previsioni in modo più generale Tralasciando per il momento predict(), alla quale dedicheremo una sezione successiva del capitolo, vediamo ora il tipo di output prodotto dalle altre: &gt; coef(comp_m1) (Intercept) ownprice 0.11043 -0.04532 &gt; anova(comp_m1) Analysis of Variance Table Response: mktshare Df Sum Sq Mean Sq F value Pr(&gt;F) ownprice 1 0.00428 0.00428 25.6 1.7e-06 *** Residuals 111 0.01855 0.00017 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Il seguente codice salva in due nuovi vettori i valori previsti dal modello per le osservazioni incluse nel campione e i relativi residui, che ricordiamo sono definiti come le differenze tra i valori osservati e quelli previsti. Queste quantità possono essere rappresentate in un grafico, chiamato grafico dei residui, che rappresenta uno strumento fondamentale per valutare la bontà del modello (ovvero delle ipotesi teoriche riguardanti gli errori): &gt; comp_m1_fitted &lt;- fitted(comp_m1) &gt; comp_m1_resid &lt;- residuals(comp_m1) &gt; plot(comp_m1_fitted, comp_m1_resid, xlab = &quot;Valori previsti&quot;, ylab = &quot;Residui&quot;) &gt; abline(h = 0, lty = 2) Figura 5.2: Grafico dei residui contro i valori previsti per il modello comp_m1. Le opzioni h e lty nel codice precedente servono rispettivamente a disegnare una linea orizzontale (in corrispondenza del valore 0 sull’asse verticale) e a scegliere il tipo di linea (il valore 2 indica una linea tratteggiata). Si usa il simbolo di tilde perché R è un software nato e sviluppato nei paesi anglosassoni e sulle tastiere US e UK tale simbolo è direttamente disponibile su uno dei tasti.↩ In generale, sui computer Mac dovreste poter recuperare il simbolo di tilde con la combinazione di tasti alt+5, ovvero il tasto option solitamente situato a sinistra della barra spaziatrice insieme al numero 5. Sulla maggior parte dei computer desktop (ma non laptop) con sistema operativo Windows, la tilde si riesce a recuperare con la combinazione di tasti Alt+126, ovvero il tasto Alt (di solito situato a sinsitra della barra spaziatrice) insieme al numero 126. Il numero 126 deve essere digitato sul tastierino numerico della tastiera (ovvero non dovete usare i numeri posti sopra la parte centrale della tastiera). Purtroppo, sui laptop la posizione di questo simbolo dipende dalla tastiera e dal brand del laptop stesso, per cui vi invitiamo a consultare le istruzioni del vostro laptop.↩ Ciò è necessario perché le variabili di un data frame non sono disponibili come oggetti autonomi nella memoria di R, a meno che non abbiate prima usato attach().↩ L’opzione lwd consente di scegliere lo spessore della linea, mentre col permette di scegliere il colore.↩ "],
["il-modello-di-regressione-lineare-multipla.html", "5.2 Il modello di regressione lineare multipla", " 5.2 Il modello di regressione lineare multipla Nella maggioranza delle applicazioni esistono molte variabili disponibili nel data set che possono contribuire a spiegare i valori osservati della variabile dipendente per ottenere modelli con una più elevata capacità predittiva. Lo strumento che si utilizza in questi casi è il modello di regressione lineare multipla, che si differenzia da quello semplice perché consente di inserire nel modello un numero qualsiasi di regressori. Il modello multiplo è definito come \\[\\begin{equation} Y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_K x_{Ki} + \\varepsilon_i, \\quad i=1,\\ldots,n, \\tag{5.4} \\end{equation}\\] dove la notazione ha lo stesso significato visto per la regressione semplice. In aggiunta all’equazione (5.4), il modello di regressione di lineare multipla è basato anche sulle seguenti ipotesi: le osservazioni \\(x_{ji}\\) sono costanti o realizzazioni di una variabile aleatoria \\(X_j\\) (\\(j=1,\\ldots,K\\)) non correlata con le componenti aleatorie di errore, \\(\\varepsilon_i\\). In quest’ultimo caso l’inferenza è svolta condizionatamente ai valori osservati di \\(X_j\\) gli errori aleatori, \\(\\varepsilon_i\\), sono variabili aleatorie con media 0 e varianza \\(\\sigma^2\\) costante per ogni \\(i = 1,\\ldots,n\\) (omoschedasticità) gli errori aleatori, \\(\\varepsilon_i\\), non sono correlati tra loro non esiste una relazione lineare che lega tra loro le variabili indipendenti gli errori aleatori, \\(\\varepsilon_i\\), sono distribuiti secondo una distribuzione normale Le funzioni disponibili in R per stimare e analizzare un modello di regressione lineare multipla sono esattamente le stesse già presentate nella Sezione 5.1, salvo che ora la formula da specificare all’interno della funzione lm() impiegherà più di una variabile a destra del simbolo di tilde. Le variabili indipendenti che vogliamo usare nel modello devono essere semplicemente aggiunte una dopo l’altra con il simbolo +. Per esempio, per generalizzare il modello semplice comp_m1 presentato sopra includendo anche le variabili relative ai prezzi dei concorrenti, dobbiamo eseguire il codice seguente: &gt; comp_m2 &lt;- lm(mktshare ~ ownprice + comp1price + comp2price, data = comp) &gt; summary(comp_m2) Call: lm(formula = mktshare ~ ownprice + comp1price + comp2price, data = comp) Residuals: Min 1Q Median 3Q Max -0.01796 -0.00583 -0.00198 0.00427 0.03936 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.04007 0.01405 2.85 0.0052 ** ownprice -0.07642 0.00796 -9.60 3.4e-16 *** comp1price 0.02633 0.00839 3.14 0.0022 ** comp2price 0.04597 0.00782 5.88 4.5e-08 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.00997 on 109 degrees of freedom Multiple R-squared: 0.526, Adjusted R-squared: 0.513 F-statistic: 40.3 on 3 and 109 DF, p-value: &lt;2e-16 Il modello stimato è quindi dato da \\[\\begin{equation} \\widehat{\\mbox{mktshare}}_i = 0.0401 -0.0764 \\, \\mbox{ownprice}_i + 0.0263 \\, \\mbox{comp1price}_i + 0.0460 \\, \\mbox{comp2price}_i. \\tag{5.5} \\end{equation}\\] L’output è strutturato esattamente come per il modello semplice, salvo che ora la tabella dei coefficienti stimati (Coefficients) contiene un numero maggiore di righe, ognuna relativa ad uno dei coefficienti del modello. Le funzioni accessorie descritte per il modello semplice (coef(), residuals(), ecc.) continuano a valere anche per il modello multiplo: &gt; coef(comp_m2) (Intercept) ownprice comp1price comp2price 0.04007 -0.07642 0.02633 0.04597 &gt; anova(comp_m2) Analysis of Variance Table Response: mktshare Df Sum Sq Mean Sq F value Pr(&gt;F) ownprice 1 0.00428 0.00428 43.1 1.8e-09 *** comp1price 1 0.00429 0.00429 43.2 1.8e-09 *** comp2price 1 0.00343 0.00343 34.6 4.5e-08 *** Residuals 109 0.01082 0.00010 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; comp_m2_fitted &lt;- fitted(comp_m2) &gt; comp_m2_resid &lt;- residuals(comp_m2) &gt; plot(comp_m2_fitted, comp_m2_resid, xlab = &quot;Valori previsti&quot;, ylab = &quot;Residui&quot;) &gt; abline(h = 0, lty = 2) Figura 5.3: Grafico dei residui contro i valori previsti per il modello comp_m2. "],
["come-calcolare-le-previsioni-per-un-modello-di-regressione-lineare.html", "5.3 Come calcolare le previsioni per un modello di regressione lineare", " 5.3 Come calcolare le previsioni per un modello di regressione lineare Uno dei motivi della popolarità del modello di regressione lineare consiste nella possibilità di calcolare previsioni in relazione a scenari che non sono stati necessariamente osservati nel campione. Nel corso abbiamo visto che esistono due tipi di previsioni, quella per il valor medio della variabile dipendente e quella per il valore individuale, le quali differiscono per il diverso standard error, nel secondo caso maggiore che nel primo. R permette di calcolare le previsioni per un modello di regressione lineare attraverso la funzione predict(), la quale richiede vengano specificati i seguenti argomenti: object, ovvero l’oggetto restituito dalla funzione lm() contenente i risultati della stima newdata, che indica un nuovo data frame contenente i valori delle variabili indipendenti da utilizzare per il calcolo delle previsioni interval, che può assumere solo tre possibili valori, ovvero confidence se si desidera calcolare gli intervalli di confidenza per la previsione del valore medio, prediction se si desidera calcolare gli intervalli di previsione per i valori individuali, none se non si vuole calcolare nessun intervallo level, il quale consente di specificare il livello di confidenza per il calcolo degli intervalli di confidenza o previsione Bisogna porre particolare attenzione nell’uso della funzione predict(), soprattutto nello specificare correttamente il data frame newdata. Questo data frame può contenere un numero arbitrario di righe, ognuna delle quali si riferisce ad uno scenario (ovvero ad una combinazione di valori delle variabili indipendenti) in cui si intende calcolare la previsione, ma deve contenere lo stesso numero di colonne inserite nel modello. Le colonne di newdata devono essere obbligatoriamente denominate con gli stessi nomi delle variabili nel modello stimato. In caso contrario, R non riuscirà ad associare le variabili inserite nel modello con quelle incluse nel data frame newdata. Supponiamo per esempio che, con riferimento al modello multiplo comp_m2, ci interessi calcolare le previsioni e i relativi intervalli di previsione al 95% per i seguenti due scenari44: &gt; data_for_predict &lt;- data.frame(ownprice = c(1.60, 1.80), + comp1price = c(1.65, 1.90), + comp2price = c(1.50, 1.75)) &gt; data_for_predict ownprice comp1price comp2price 1 1.6 1.65 1.50 2 1.8 1.90 1.75 Il data frame data_for_predict contiene quindi due righe, una per ciascun scenario, e tre colonne i cui nomi corrispondono a quelli del data frame contenente il campione (ovvero comp). Ora usiamo la funzione predict() per calcolare le previsioni: &gt; predict(object = comp_m2, newdata = data_for_predict, + interval = &quot;prediction&quot;, level = 0.95) fit lwr upr 1 0.03019 0.01020 0.05018 2 0.03298 0.01296 0.05301 L’output restituito da predict() consiste in una matrice con due righe corrispondenti ai due scenari considerati e tre colonne contenenti rispettivamente le previsioni (fit) e i limiti degli intervalli di previsione (lwr e upr). Il segno + che vedete all’inizio della seconda e terza riga di codice viene aggiunto da R e indica semplicemente che il codice nella prima linea prosegue nelle righe successive, ma non dovete scriverlo quando provate a riprodurre il codice.↩ "],
["le-osservazioni-influenti.html", "5.4 Le osservazioni influenti", " 5.4 Le osservazioni influenti Una volta che abbiamo stimato il modello di regressione lineare, è necessario eseguire una serie di verifiche per controllare che le ipotesi del modello siano soddisfatte e per valutare che non ci siano troppe osservazioni che esercitano un’influenza particolarmente forte sui risultati della stima. Ora presentiamo alcune funzioni disponibli in R per identificare queste ultime. Due funzioni di R utili per identificare la presenza di osservazioni potenzialmente influenti sono rstandard() e hatvalues(), che restituiscono rispettivamente i residui standardizzati e i cosiddetti effetti-leva (in inglese leverage). Entrambe le funzioni richiedono solo che venga specificato il modello stimato e producono in output un vettore numerico contenenti tali quantità. Entrambe queste misure possono essere rappresentate in un grafico per evidenziare i valori più critici. Il codice seguente calcola e produce il grafico dei residui standardizzati per il modello multiplo comp_m2: &gt; stdres &lt;- rstandard(comp_m2) &gt; plot(stdres, ylim = c(min(stdres, -3), max(stdres, 3)), + xlab = &quot;Indice di riga&quot;, ylab = &quot;Residui standardizzati&quot;, type = &quot;n&quot;) &gt; text(x = stdres, labels = 1:nrow(comp), cex = 0.5) &gt; abline(h = c(-2, 0, 2), lty = 2) Figura 5.4: Grafico dei residui standardizzati per il modello comp_m2. Notate che nella funzione plot() abbiamo utilizzato l’argomento type = &quot;n&quot; (che sta per “nothing”), il quale consente di preparare gli assi del grafico, ma di non disegnare i punti. Questi vengono aggiunti con la successiva riga di codice attraverso la funzione text(), che sovrappone un’etichetta di testo in corrispondenza delle coordinate dei punti (x = stdres). In questo esempio le etichette di testo usate sono i numeri di riga delle osservazioni (labels = 1:nrow(comp)). Ciò permette di identificare direttamente dal grafico quali sono le osservazioni con un residuo standardizzato particolarmente grande (in valore assoluto). Le soglie oltre le quali le osservazioni vengono di solito classificate come outlier sono -2 e +2 (aggiunte nel grafico per mezzo della funzione abline()). In questo caso ci sono 7 osservazioni outlier, ovvero la numero 2, 3, 45, 71, 89, 103 e 113. Il codice seguente calcola e produce il grafico dei leverage per lo stesso modello: &gt; lev &lt;- hatvalues(comp_m2) &gt; lev_thr &lt;- 2*mean(lev) &gt; plot(lev, ylim = c(0, max(lev, lev_thr)), + xlab = &quot;Indice di riga&quot;, ylab = &quot;Effetto-leva&quot;, type = &quot;n&quot;) &gt; text(x = lev, labels = 1:nrow(comp), cex = 0.5) &gt; abline(h = lev_thr, lty = 2) Figura 5.5: Grafico dei leverage per il modello comp_m2. Per i leverage la soglia comunemente utilizzata è pari a due volte la media dei leverage (che nel precedente codice è memorizzata nell’oggetto lev_thr). Per questo modello ci sono 7 osservazioni con elevato leverage, ovvero la numero 2, 88, 93, 94, 96, 104 e 108. "],
["appendix.html", "Capitolo 6 Appendice", " Capitolo 6 Appendice In questa appendice presentiamo alcuni approfondimenti non necessari per il corso 30001 (Statistica), ma che consentono di ottenere output più dettagliati rispetto a quanto proposto da Radiant. Tali elementi possono essere utili per corsi futuri in cui si utilizza R o per analisi di data set legati al lavoro finale di triennio o alla tesi di biennio. "],
["alcune-funzioni-di-r-per-la-statistica-descrittiva.html", "6.1 Alcune funzioni di R per la statistica descrittiva", " 6.1 Alcune funzioni di R per la statistica descrittiva 6.1.1 Analisi descrittive univariate 6.1.1.1 Una singola variabile categorica Nel caso ci interessi sintetizzare le informazioni relative ad una variabile categorica, gli strumenti che possiamo utilizzare sono la distribuzione di frequenze insieme ad una rappresentazione grafica della stessa. Prima di mostrare alcuni esempi, vi ricordiamo che in R le variabili categoriche corrispondono a vettori di tipo factor, che abbiamo presentato nella Sezione 1.3.4. Se la variabile che intendete analizzare non fosse codificata come factor, dovete prima convertirla in quel formato usando la funzione as.factor(). Ad esempio, per convertire la variabile numerica IndustryCode nel data frame forbes94 dobbiamo eseguire il codice seguente: &gt; load(&quot;Forbes94.RData&quot;) &gt; forbes94$IndustryCode &lt;- as.factor(forbes94$IndustryCode) &gt; str(forbes94$IndustryCode) Factor w/ 20 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,..: 12 12 12 12 12 12 12 12 12 12 ... Ricordate che l’operatore $ serve per riferirsi ad una colonna di un data frame. Per costruire la distribuzione di frequenze di una variabile categorica in R dobbiamo usare la funzione table(), già descritta nella Sezione 2.1. Ad esempio, la distribuzione di frequenze della variabile categorica WideIndustry si ottiene con il codice seguente: &gt; table(forbes94$WideIndustry) Aerospacedefense Business Capital goods 19 27 19 Chemicals ComputersComm Construction 25 67 11 Consumer Energy Entertainment 54 42 27 Financial Food Forest 168 62 19 Health Insurance Metals 49 54 18 Retailing Transport Travel 46 15 15 Utility 63 Come sempre, è possibile memorizzare il risultato della funzione table() in un oggetto (si tratterebbe di un semplice vettore numerico contenente le frequenze assolute e i cui elementi sarebbero chiamati come i livelli, ovvero le modalità, della variabile) e utilizzarlo successivamente per ulteriori analisi. Per produrre la distribuzione di frequenze relative possiamo usare la funzione prop.table(), la quale richiede in input la tabella con le frequenze assolute: &gt; absfreq &lt;- table(forbes94$WideIndustry) &gt; prop.table(absfreq) Aerospacedefense Business Capital goods 0.02375 0.03375 0.02375 Chemicals ComputersComm Construction 0.03125 0.08375 0.01375 Consumer Energy Entertainment 0.06750 0.05250 0.03375 Financial Food Forest 0.21000 0.07750 0.02375 Health Insurance Metals 0.06125 0.06750 0.02250 Retailing Transport Travel 0.05750 0.01875 0.01875 Utility 0.07875 Una volta creata la distribuzione di frequenze, possiamo rappresentarla graficamente con un diagramma a torta o a barre. In R questi si ottengono rispettivamente con le funzioni pie() (già descritta nella Sezione 2.1) e barplot(), le quali richiedono in input la distribuzione di frequenze (assolute o relative): &gt; pie(absfreq, main = &quot;Distribuzione di WideIndustry&quot;) # diagramma a torta &gt; barplot(absfreq, main = &quot;Distribuzione di WideIndustry&quot;) # diagramma a barre Figura 6.1: Diagramma a torta e a barre con R. 6.1.1.2 Una singola variabile numerica 6.1.1.2.1 Distribuzione di frequenze La distribuzione di una variabile numerica è rappresentata da una tabella che riporta le frequenze con cui sono stati osservati i diversi valori, nel caso la variabile sia discreta, o le classi in cui è stata divisa, nel caso in cui la variabile sia continua. In entrambi i casi è possibile utilizzare ancora la funzione table(), ma nel caso di variabili continue sarà prima necessario dividere i valori osservati in classi. Una funzione utile per generare tali classi è cut(), che genera un vettore factor con le classi specificate e che include i seguenti argomenti: x, il vettore numerico con i valori di cui vogliamo costruire le classi breaks, che consente di specificare quali classi intendiamo usare; può essere specificato nei seguenti modi alternativi un singolo valore numerico che indica il numero di classi di uguale ampiezza che vogliamo usare un vettore di valori numerici che identificano gli estremi delle classi (eventualmente di diversa ampiezza) da usare right, un valore logico che indica se le classi devono essere chiuse a sinistra (FALSE) o a destra (TRUE) labels, un vettore di etichette da utilizzare per identificare le classi; se fissato pari a FALSE, le classi saranno identificate da dei numeri interi Per esempio, supponiamo di voler costruire la distribuzione di frequenze della variabile Salary, che fornisce lo stipendio pagato ai CEO inclusi nel data set nel 1994, usando 5 classi di uguale ampiezza chiuse a sinistra. Il seguente codice permette di creare una nuova variabile, che decidiamo di chiamare Salary_c e che aggiungiamo al data frame esistente: &gt; forbes94$Salary_c &lt;- cut(forbes94$Salary, breaks = 5, right = FALSE) &gt; table(forbes94$Salary_c) [1.59e+04,5.55e+05) [5.55e+05,1.09e+06) 382 376 [1.09e+06,1.63e+06) [1.63e+06,2.16e+06) 24 4 [2.16e+06,2.7e+06) 3 da cui si vede chiaramente che la distribuzione dei salari per questi CEO è decisamente asimmetrica a destra. Se invece volessimo utilizzare le classi \\([0, 200000)\\), \\([200000, 500000)\\), \\([500000, 800000)\\), \\([800000, 1500000)\\) e \\([1500000, 3000000]\\), allora dovremmo utilizzare la funzione cut() nel modo seguente: &gt; forbes94$Salary_c &lt;- cut(forbes94$Salary, + breaks = c(0, 200000, 500000, 800000, 1500000, 3000000), right = FALSE) &gt; table(forbes94$Salary_c) [0,2e+05) [2e+05,5e+05) [5e+05,8e+05) 13 268 351 [8e+05,1.5e+06) [1.5e+06,3e+06) 147 10 Per rappresentare graficamente la distribuzione di una variabile numerica sono disponibili vari tipi di grafici tra cui il diagramma ad aste, l’istogramma e il box-plot. 6.1.1.2.2 Diagramma ad aste Possiamo creare un diagramma ad aste usando la funzione plot() direttamente sul risultato fornito da table() e fissando l’argomento type al valore &quot;h&quot;. Ad esempio, il diagramma ad aste per la variabile Age è ottenuto come segue: &gt; plot(table(forbes94$Age), type = &quot;h&quot;) Figura 6.2: Diagramma ad aste per la variabile Age. L’aspetto finale del grafico può essere modificato attraverso gli argomenti della funzione plot(). Se ad esempio volessimo aggiungere le etichette agli assi dovremmo usare gli argomenti xlab e ylab, ovvero &gt; plot(table(forbes94$Age), type = &quot;h&quot;, + xlab = &quot;Age&quot;, ylab = &quot;Frequenza assoluta&quot;, + main = &quot;Diagramma ad aste della variabile Age&quot;) Figura 6.3: Diagramma ad aste per la variabile Age. 6.1.1.2.3 Istogramma Gli istogrammi sono rappresentazioni grafiche della distribuzione di frequenze di una variabile divisa per classi. In R è possibile creare un istogramma con la funzione hist(). Come è noto, è possibile creare un istogramma usando classi di uguale o diversa ampiezza. La funzione hist() permette di specificare tale scelta attraverso l’argomento breaks, il cui funzionamento è identico al medesimo argomento descritto per la funzione cut(), ovvero: se non specifichiamo il valore di breaks, R utilizza alcune regole interne per sceglierne un valore ragionevole; consigliamo di usare questa opzione, perché funziona bene nella maggioranza dei casi, a meno che non ci siano motivi particolari per usare una regola diversa breaks può essere specificato come singolo valore numerico (intero positivo), il quale indicherà il numero (indicativo45) di classi di uguale ampiezza che vogliamo usare breaks può anche essere specificato come vettore numerico, i cui elementi corrisponderanno agli estremi delle classi che intendiamo usare In aggiunta a breaks, la funzione hist() contiene molti altri argomenti con cui è possibile modificare l’aspetto finale del grafico, tra cui main, xlab e ylab, che funzionano in modo analogo a quanto visto finora. Vediamo ora alcuni esempi di istogrammi per la variabile Salary: &gt; hist(forbes94$Salary, main = &quot;Istogramma di Salary&quot;, xlab = &quot;Salary (in $)&quot;, + ylab = &quot;Frequenza assoluta&quot;) Figura 6.4: Esempio di istogramma per la variabile Salary (classi di uguale ampiezza). &gt; hist(forbes94$Salary, main = &quot;Istogramma di Salary&quot;, xlab = &quot;Salary (in $)&quot;, + ylab = &quot;Frequenza assoluta&quot;, breaks = 50) Figura 6.5: Esempio di istogramma per la variabile Salary (classi di uguale ampiezza). &gt; hist(forbes94$Salary, main = &quot;Istogramma di Salary&quot;, xlab = &quot;Salary (in $)&quot;, + ylab = &quot;Densità di frequenze&quot;, + breaks = c(0, 100000, 300000, 350000, 500000, 800000, 1000000, 3000000)) Figura 6.6: Esempio di istogramma per la variabile Salary (classi di diversa ampiezza). Questi esempi mostrano chiaramente che la distribuzione di Salary è asimmetrica a destra. Vi facciamo inoltre notare che nell’ultimo esempio, in cui abbiamo utilizzato 7 classi di diversa ampiezza, R ha automaticamente (e correttamente!) deciso di riportare sull’asse verticale la densità di frequenze, mentre nei due esempi precedenti sull’asse verticale ha riportato le frequenze assolute delle classi. Anche nel caso di classi di uguale ampiezza è possibile costruire l’istogramma con le densità fissando a FALSE il valore dell’argomento freq46. 6.1.1.2.4 Box-plot In aggiunta al diagramma ad aste e all’istogramma, è utile produrre anche il box-plot, che consente di integrare le informazioni fornite dagli altri grafici. Come abbiamo già visto nella Sezione 2.1, in R è possibile costruire un box-plot attraverso la funzione boxplot(). Ricordiamo che il box-plot della variabile Salary si ottiene come segue: &gt; boxplot(forbes94$Salary) Figura 6.7: Esempio di box-plot con R. Un utile commento finale su boxplot() riguarda la possibilità di salvare output aggiuntivo rispetto al grafico. In particolare, boxplot() consente di salvare in una lista (vedi la Sezione 1.3.6) i valori degli indici che servono per costruire il grafico. Per esempio, per la variabile Salary otteniamo &gt; bp_out &lt;- boxplot(forbes94$Salary) &gt; str(bp_out) List of 6 $ stats: &#39;integer&#39; num [1:5, 1] 18600 433333 569231 750000 1200000 $ n : num 789 $ conf : num [1:2, 1] 551419 587043 $ out : num [1:18] 1750000 1400000 1500000 1375000 2000000 ... $ group: num [1:18] 1 1 1 1 1 1 1 1 1 1 ... $ names: chr &quot;1&quot; Come vedete, bp_out è una lista che contiene 6 elementi (ovvero altri oggetti), tra cui stats, che contiene i valori dei 5 indici necessari per costruire il box-plot (minimo, primo quartile, mediana, terzo quartile e massimo), e out, il vettore delle osservazioni outlier. Concludiamo quindi che nella distribuzione di Salary risultano essere presenti 18 outlier: [1] 1750000 1400000 1500000 1375000 2000000 1900000 [7] 1250000 1483500 1454000 2633570 1240000 1841000 [13] 1231730 2667730 2700000 1525000 1397810 1504940 6.1.1.2.5 Indici di sintesi Le principali funzioni disponibili in R per il calcolo di indici di sintesi per una variabile numerica sono: min(), per il calcolo del minimo valore osservato di una variabile max(), per il calcolo del massimo valore osservato di una variabile mean(), per il calcolo della media campionaria median(), per il calcolo della mediana campionaria var(), per il calcolo della varianza campionaria sd(), per il calcolo della deviazione standard campionaria quantile(), per il calcolo dei quantili campionari summary(), la quale fornisce in automatico una lista con alcuni degli indici sopra citati Nel caso la variabile contenesse dei valori mancanti (ovvero NA), queste funzioni ad eccezione di summary() richiedono venga fissato a TRUE il valore dell’argomento na.rm, tramite il quale indichiamo ad R di rimuovere internamente (ma non dal data set) i dati mancanti prima di effettuare il calcolo. Vediamo un esempio usando sempre la variabile Salary: &gt; min(forbes94$Salary, na.rm = TRUE) [1] 18600 &gt; max(forbes94$Salary, na.rm = TRUE) [1] 2700000 &gt; mean(forbes94$Salary, na.rm = TRUE) [1] 613458 &gt; median(forbes94$Salary, na.rm = TRUE) [1] 569231 &gt; var(forbes94$Salary, na.rm = TRUE) [1] 7.858e+10 &gt; sd(forbes94$Salary, na.rm = TRUE) [1] 280319 &gt; quantile(forbes94$Salary, na.rm = TRUE) 0% 25% 50% 75% 100% 18600 433333 569231 750000 2700000 &gt; summary(forbes94$Salary) Min. 1st Qu. Median Mean 3rd Qu. Max. 18600 433333 569231 613458 750000 2700000 NA&#39;s 11 La funzione quantile() consente di calcolare i percentili di un set di dati numerici. L’ordine dei percentili che vogliamo calcolare viene specificato attraverso l’argomento probs. Per esempio, i percentili di ordine 10 e 95 per la variabile Salary sono calcolati come segue: &gt; quantile(forbes94$Salary, na.rm = TRUE, probs = c(0.10, 0.95)) 10% 95% 325149 1025640 6.1.2 Analisi descrittive bivariate 6.1.2.1 Due variabili categoriche Nel caso volessimo analizzare congiuntamente due variabili categoriche, lo strumento principale da utilizzare consiste nella tabella a doppia entrata. In R possiamo costruire una tabella a doppia entrata con la funzione table(), che abbiamo già incontrato in varie occasioni. Per ottenere una tabella a doppia entrata bisogna però specificare due variabili, rispettivamente la variabile di riga e quella di colonna (in quest’ordine). Il codice seguente permette di costruire la tabella a doppia entrata per la variabile MBA contro WideIndustry: &gt; table(forbes94$WideIndustry, forbes94$MBA) 0 1 Aerospacedefense 15 4 Business 22 5 Capital goods 13 6 Chemicals 17 8 ComputersComm 46 21 Construction 7 4 Consumer 36 18 Energy 32 10 Entertainment 23 4 Financial 112 56 Food 45 17 Forest 12 7 Health 37 12 Insurance 43 11 Metals 14 4 Retailing 43 3 Transport 11 4 Travel 13 2 Utility 48 15 La rappresentazione grafica di una tabella a doppia entrata tramite un diagramma a barre sovrapposte si ottiene con la funzione plot() in cui le variabili devono essere specificate attraverso una formula: &gt; plot(MBA ~ WideIndustry, data = forbes94) Figura 6.8: Grafico a barre sovrapposte per la variabile MBA rispetto a WideIndustry. 6.1.2.2 Due variabili numeriche In R è possibile creare un diagramma di dispersione con la funzione plot() in cui specifichiamo come prima la variabile \\(x\\) e come seconda la \\(y\\)47. Come per le altre funzioni grafiche, possiamo aggiungere anche altri argomenti con i quali possiamo modificare l’aspetto finale del grafico. Il codice che segue crea il diagramma di dispersione per la variabile Salary contro la variabile Age: &gt; plot(forbes94$Age, forbes94$Salary, xlab = &quot;Age (in years)&quot;, + ylab = &quot;Salary (in $)&quot;, main = &quot;Diagramma di dispersione&quot;) Figura 6.9: Diagramma di dispersione per la variabile Salary rispetto a Age. Per il calcolo della covarianza e dell’indice di correlazione lineare campionari possiamo usare rispettivamente le funzioni cov() e cor(). Nel caso includessimo in queste funzioni più di due variabili, queste restituirebbero in output rispettivamente le matrici delle covarianze e delle correlazioni lineari campionarie. Se alcune delle variabili contengono dei dati mancanti, è opportuno includere in queste funzioni anche l’argomento use fissandolo al valore &quot;complete.obs&quot;48. Per calcolare le covarianze e le correlazioni tra le variabili Age, Salary, Bonus e Other possiamo eseguire il codice che segue: &gt; cov(forbes94[, c(&quot;Age&quot;, &quot;Salary&quot;, &quot;Bonus&quot;, &quot;Other&quot;)], + use = &quot;complete.obs&quot;) Age Salary Bonus Other Age 41.59 4.059e+05 7.083e+05 4.465e+05 Salary 405931.80 6.886e+10 6.194e+10 9.696e+10 Bonus 708346.61 6.194e+10 8.676e+11 4.023e+11 Other 446454.17 9.696e+10 4.023e+11 1.671e+12 &gt; cor(forbes94[, c(&quot;Age&quot;, &quot;Salary&quot;, &quot;Bonus&quot;, &quot;Other&quot;)], + use = &quot;complete.obs&quot;) Age Salary Bonus Other Age 1.00000 0.2399 0.1179 0.05356 Salary 0.23987 1.0000 0.2534 0.28583 Bonus 0.11792 0.2534 1.0000 0.33416 Other 0.05356 0.2858 0.3342 1.00000 Le correlazioni tra queste variabili sono tutte positive, ma comunque deboli o molto deboli. Ciò è dovuto principalmente alla presenza di numerosi outlier e all’eterogeneità dei valori osservati. 6.1.3 Ulteriori rappresentazioni grafiche 6.1.3.1 Il diagramma di Pareto Il diagramma di Pareto è una rappresentazione grafica utile per separare le modalità di una variabile categorica che sono state osservate più frequentemente da quelle meno frequenti. Purtroppo non c’è nessuna funzione nei pacchetti base di R che consente di produrre un diagramma di Pareto. Tuttavia, è possibile scaricare e installare un pacchetto aggiuntivo, chiamato qcc, che contiene alcune funzioni dedicate al controllo statistico della qualità in produzione, tra cui anche una funzione per disegnare il diagramma di Pareto. Possiamo installare il pacchetto seguendo le istruzioni riportate in Sezione 1.5 o in alternativa eseguendo il codice seguente: &gt; install.packages(&quot;qcc&quot;) # scarica il pacchetto qcc &gt; library(qcc) # carica il pacchetto qcc Il pacchetto qcc contiene una funzione chiamata pareto.chart() che consente di produrre direttamente il diagramma di Pareto. Questa funzione richiede che venga fornito in input un vettore numerico con le frequenze assolute con cui si sono osservate le varie modalità. Per ottenere un grafico più informativo, consigliamo anche di assegnare dei nomi agli elementi del vettore, i quali saranno riportati sull’asse orizzontale del grafico. Il seguente codice dapprima carica alcuni dati contenuti nel data frame pareto_dat e relativi al numero di pezzi difettosi rilevati in un’azienda (colonna Total), insieme alla corrispondente causa di difettosità (colonna Cause), e successivamente utilizza questi dati per costruire il diagramma di Pareto: &gt; load(&quot;pareto_data.RData&quot;) &gt; pdat &lt;- pareto_dat$Total &gt; names(pdat) &lt;- pareto_dat$Cause &gt; pareto.chart(data = pdat, main = &quot;Diagramma di Pareto&quot;) Figura 6.10: Esempio di diagramma di Pareto ottenuto con la funzione pareto.chart() del pacchetto qcc. Pareto chart analysis for pdat Frequency Cum.Freq. Compressor 15.000 15.000 Machine adjustment 11.000 26.000 Packing 10.000 36.000 Supplier 9.000 45.000 Operation conditions 8.000 53.000 Transport agency 3.000 56.000 Measurement apparatus 3.000 59.000 Receptionist 2.000 61.000 Transport method 2.000 63.000 Recording method 2.000 65.000 Recording Operator 1.000 66.000 Storage operators 1.000 67.000 Raw materials reception 1.000 68.000 Pareto chart analysis for pdat Percentage Cum.Percent. Compressor 22.059 22.059 Machine adjustment 16.176 38.235 Packing 14.706 52.941 Supplier 13.235 66.176 Operation conditions 11.765 77.941 Transport agency 4.412 82.353 Measurement apparatus 4.412 86.765 Receptionist 2.941 89.706 Transport method 2.941 92.647 Recording method 2.941 95.588 Recording Operator 1.471 97.059 Storage operators 1.471 98.529 Raw materials reception 1.471 100.000 6.1.3.2 Rappresentazione grafica di una serie storica Un’altra situazione che si incontra di frequente quando si analizzano dei dati è quella in cui le osservazioni sono ordinate temporalmente. Questo tipo di dati vengono chiamati serie storiche. La funzione ts() consente di creare una serie storica e di definirne le caratteristiche in termini di numero di osservazioni per anno, data di inizio e data di fine. A titolo di esempio, carichiamo il file advertising_sales.RData, che contiene il data frame advertising_sales con le serie storiche mensili delle vendite e delle spese in pubblicità (entrambe in migliaia di dollari) di un prodotto per il fitness. I dati disponibili sono stati raccolti a partire dal mese di gennaio 2012. Il seguente codice permette di definire i dati come serie storiche applicando la funzione ts() con l’argomento frequency fissato a 12 (ovvero 12 osservazioni in un anno) e l’argomento start al vettore c(2012, 1), che indicano rispettivamente l’anno e il mese a cui fa riferimento la prima osservazione. Infine, con la funzione plot() creiamo il grafico temporale delle due serie, che rappresentiamo con colori e tipo di linee (argomenti col e lty) diversi49: &gt; load(&quot;advertising_sales.RData&quot;) &gt; adv_sales &lt;- ts(advertising_sales[, c(2, 3)], frequency = 12, start = c(2012, 1)) &gt; plot(adv_sales, plot.type = &quot;single&quot;, col = c(&quot;red&quot;, &quot;blue&quot;), + lwd = 2, lty = c(1, 2), ylab = &quot;&quot;, main = &quot;Grafico per serie storiche&quot;, + sub = &quot;(linea continua = spese in pubblicità, linea tratteggiata = vendite)&quot;) Figura 6.11: Esempio di grafico per serie storiche. 6.1.3.3 Come verificare se una variabile è distribuita in modo normale Molti modelli statistici richiedono che le popolazioni di riferimento siano distribuite seconda una normale. Pertanto, è necessario verificare che questa ipotesi sia almeno approssimativamente soddisfatta dai dati campionari che stiamo analizzando. In caso contrario, i risultati che otterremo dalle analisi potrebbero essere distorti e non attendibili. Uno strumento semplice ma efficace per verificare la normalità di una distribuzione di un set di dati numerici è il normal probability plot, che si può creare in R attraverso la funzione qqnorm(). Questa funzione richiede solo l’indicazione della variabile da usare, oltre eventualmente ad altri argomenti per migliorare l’aspetto del grafico (main, xlab, ylab, col, ecc.). Dopo aver eseguito qqnorm(), la funzione qqline() consente di aggiungere al grafico una retta che aiuta a valutare la vicinanza della distribuzione empirica dei dati alla distribuzione normale. Anche questa funzione richiede obbligatoriamente di indicare solamente il nome della variabile oggetto dell’analisi. Il seguente codice genera il normal probability plot per la variabile Salary: &gt; qqnorm(forbes94$Salary, main = &quot;Normal probability plot di Salary&quot;) &gt; qqline(forbes94$Salary) Figura 6.12: Esempio di normal probability plot per la variabile Salary. Dal grafico si conclude che la distribuzione di Salary è asimmetrica a destra e pertanto non si può ritenere distribuita come una normale. Come secondo esempio consideriamo la variabile Age: &gt; qqnorm(forbes94$Age, main = &quot;Normal probability plot di Age&quot;) &gt; qqline(forbes94$Age) Figura 6.13: Esempio di normal probability plot per la variabile Age. In questo caso la distribuzione empirica di Age è molto più vicina, anche se non perfettamente, ad una distribuzione normale50. Come è indicato anche nell’help della funzione hist(), infatti, il valore che forniamo per il numero di classi di uguale ampiezza è solo un “suggerimento”, ma internamente tale valore viene rivisto in funzione di alcune regole, che non è nostro obiettivo descrivere ora.↩ Se provaste a fissare freq = TRUE nel caso di classi di diversa ampiezza, otterreste un istruttivo messaggio di errore.↩ In alternativa, è possibile specificare le variabili attraverso una formula, ad esempio plot(Salary $\\sim$ Age, data = forbes94).↩ Sono disponibili altre scelte per l’argomento use, ma non le presentiamo in questo manuale. Vi invitiamo comunque a leggere l’help di queste funzioni.↩ Gli argomenti lwd, lty e sub servono per definire lo spessore della linea (2 significa linee spesse il doppio del normale), il tipo di linea (1 significa una linea continua, mentre 2 una linea tratteggiata) e un sottotitolo, riportato nella parte bassa del grafico.↩ Ricordiamo che il normal probability plot è uno strumento grafico e pertanto aiuta a discriminare bene se ci troviamo vicino alla situazione di normalità o meno solo nei casi più evidenti. In molte situazioni il grafico non consente di arrivare ad una conclusione univoca sulla normalità. In questi casi è necessario utilizzare strumenti più elaborati che non sono oggetto di discussione né qui né nel corso.↩ "],
["alcune-funzioni-r-per-la-statistica-inferenziale.html", "6.2 Alcune funzioni R per la statistica inferenziale", " 6.2 Alcune funzioni R per la statistica inferenziale In questa sezione mostriamo come effettuare con R le analisi inferenziali presentate nel corso. 6.2.1 Inferenza sulla media di una popolazione normale E’ possibile fare inferenza su una media \\(\\mu\\) di una popolazione normale assumendo che la varianza \\(\\sigma^2\\) della popolazione sia nota oppure no. In questa sezione ci occupiamo solo del secondo caso perché si tratta della situazione più frequente e rilevante nella pratica dell’analisi dei dati. Inoltre, né R né Radiant mettono a disposizione funzioni o comandi che consentono di ottenere rapidamente i risultati nel caso in cui la varianza fosse nota. Oltre alle funzioni mean e sd già discusse nella Sezione 6.1.1.2.5 per la stima rispettivamente della media e della deviazione standard di un popolazione, R mette a disposizione la funzione t.test() che consente di gestire tutti i casi presentati nel corso per quanto riguarda l’inferenza su medie. La funzione t.test() restituisce contemporaneamente l’intervallo di confidenza e il test relativo al caso considerato. Nel caso di inferenza su una singola media per una popolazione normale, gli argomenti da specificare sono: x, variabile su cui effettuare le analisi alternative, tipo di ipotesi alternativa che vogliamo usare, ovvero bilaterale (two.sided) o unilaterale (less o greater, a seconda del segno previsto da \\(H_1\\)) mu, valore della media che vogliamo testare sotto \\(H_0\\) (la quantità che nel corso è stata chiamata \\(\\mu_0\\)) conf.level, livello di confidenza che si desidera usare Vediamo subito un esempio usando ancora una volta i dati contenuti nel data frame forbes94. In particolare, definiamo una nuova variabile che chiamiamo ROS, ovvero return on sales, calcolata come il rapporto percentuale dei profitti e i ricavi di vendita: &gt; forbes94 &lt;- transform(forbes94, ROS = Profits/Sales*100) Procediamo ora a calcolare l’intervallo di confidenza al 90% per la media della variabile ROS. Inoltre, insieme all’intervallo effettueremo un test per verificare se i dati supportano la conclusione che la media del ROS per la popolazione di aziende da cui questo campione è stato estratto sia diversa dal 6%. In altri termini, indicata con \\(\\mu\\) la media non nota del ROS nella popolazione, con il test confronteremo le seguenti ipotesi \\[\\begin{equation*} H_0: \\mu = 6\\% \\qquad \\mbox{vs.} \\qquad H_1: \\mu \\ne 6\\%. \\end{equation*}\\] Come detto, tutti questi risultati possono essere recuperati in un colpo solo tramite la funzione t.test() come segue: &gt; t.test(x = forbes94$ROS, alternative = &quot;two.sided&quot;, mu = 6, conf.level = 0.90) One Sample t-test data: forbes94$ROS t = 4.2, df = 800, p-value = 3e-05 alternative hypothesis: true mean is not equal to 6 90 percent confidence interval: 6.780 7.798 sample estimates: mean of x 7.289 I risultati indicano che l’intervallo di confidenza al 90% è pari a \\((6.7799, 7.7978)\\), mentre il test restituisce un p-value molto piccolo, riportato come 3.377e-0551, il quale permette di rifiutare ampiamente l’ipotesi anche usando un livello di significatività \\(\\alpha\\) di 0.01. 6.2.2 Inferenza sulla proporzione di successi in una popolazione bernoulliana In analogia a quanto visto per la media di una popolazione normale, la funzione prop.test() fornisce i medesimi calcoli per la proporzione di successi di una popolazione bernoulliana. Gli argomenti della funzione sono: x, numero di successi osservati nelle \\(n\\) osservazioni campionarie n, dimensione del campione p, valore della proporzione \\(p_0\\) che vogliamo testare sotto l’ipotesi nulla alternative, tipo di test che vogliamo effettuare, ovvero se bilaterale (two.sided) o unilaterale (less o greater, a seconda della direzione richiesta in \\(H_1\\)) conf.level, livello di confidenza che si desidera usare correct, con cui è possibile indicare ad R se usare o meno una correzione, detta di Yates, che non è stata presentata nel corso e che quindi noi fisseremo sempre al valore FALSE Anche in questo caso, la funzione prop.test() calcola automaticamente sia l’intervallo di confidenza sia il test sulla proporzione. Supponiamo di voler stimare la proporzione di CEO con il titolo di MBA nella popolazione di riferimento usando il campione disponibile nel data frame forbes94. In aggiunta, vogliamo anche calcolarne l’intervallo di confidenza al 99% e ci interessa testare l’ipotesi nulla che la proporzione di CEO in possesso del titolo di MBA nella popolazione sia uguale al 30%. Il codice seguente consente di effettuare congiuntamente queste analisi: &gt; prop.test(x = sum(forbes94$MBA == &quot;1&quot;), n = nrow(forbes94), p = 0.3, + alternative = &quot;two.sided&quot;, conf.level = 0.99, correct = FALSE) 1-sample proportions test without continuity correction data: sum(forbes94$MBA == &quot;1&quot;) out of nrow(forbes94), null probability 0.3 X-squared = 5, df = 1, p-value = 0.03 alternative hypothesis: true p is not equal to 0.3 99 percent confidence interval: 0.2257 0.3057 sample estimates: p 0.2637 Notate che per calcolare il numero di successi abbiamo usato il codice sum(forbes94$MBA == &quot;1&quot;), ovvero abbiamo prima verificato con l’operatore logico == per quali osservazioni abbiamo osservato un “successo” (cioè un valore pari a &quot;1&quot;) e abbiamo calcolato la somma (sum()) del vettore logico risultante52. I risultati indicano che l’intervallo di confidenza al 99% è pari a \\((0.2257, 0.3057)\\)53, mentre il p-value del test, pari a 0.02526, ci suggerisce che esiste sufficiente evidenza empirica proveniente dai dati per rifiutare l’ipotesi nulla \\(H_0: p = 0.30\\) ad un livello di significatività \\(\\alpha\\) di 0.05, ma non di 0.01. 6.2.3 Inferenza sul confronto tra le medie di due popolazioni normali Il caso della differenza tra due medie è uno di quelli più utilizzati nelle applicazioni e nel corso ne sono state presentate alcune varianti, in particolare: confronto tra due medie di due popolazioni normali con varianze note, campioni indipendenti confronto tra due medie di due popolazioni normali con varianze non note ma assunte uguali, campioni indipendenti confronto tra due medie di due popolazioni normali con varianze non note, campioni dipendenti In R non sono disponibili strumenti per il primo caso, che quindi non presenteremo qui. Per confrontare due medie di due popolazioni normali in R possiamo utilizzare ancora la funzione t.test(), ma rispetto al caso di una singola media dovremo ora fornire i seguenti argomenti: x, valori osservati per il primo campione y, valori osservati per il secondo campione alternative, tipo di test che vogliamo effettuare, ovvero se bilaterale (two.sided) o unilaterale (less o greater, a seconda della direzione richiesta in \\(H_1\\)) mu, valore della differenza delle medie che vogliamo testare sotto l’ipotesi nulla paired, che indica se i campioni sono indipendenti (FALSE) o dipendenti (TRUE) var.equal, che indica se le varianze (non note) delle due popolazioni nel caso di campioni indipendenti si assumono uguali (TRUE) o diverse (FALSE) conf.level, livello di confidenza che ci interessa usare 6.2.3.1 Campioni indipendenti Vediamo subito un esempio di confronto tra due medie di due popolazioni normali con varianze non note ma uguali e campioni indipendenti. In particolare, confrontiamo la media della variabile ROS nei due gruppi identificati dalla variabile MasterPhd, che indica quali dei CEO nel 1994 possedeva un titolo di Master o di PhD. Calcoliamo l’intervallo di confidenza al 95% e effettuiamo il test per verificare se le due medie nella popolazione sono uguali, ovvero \\[\\begin{equation*} H_0: \\mu_{(\\mbox{MasterPhd}=0)} = \\mu_{(\\mbox{MasterPhd}=1)} \\quad \\mbox{vs.} \\quad H_1: \\mu_{(\\mbox{MasterPhd}=0)} \\ne \\mu_{(\\mbox{MasterPhd}=1)}. \\end{equation*}\\] Il codice seguente consente di ottenere queste analisi: &gt; ROS_0 &lt;- forbes94$ROS[forbes94$MasterPhd == &quot;0&quot;] &gt; ROS_1 &lt;- forbes94$ROS[forbes94$MasterPhd == &quot;1&quot;] &gt; t.test(ROS_0, ROS_1, alternative = &quot;two.sided&quot;, mu = 0, paired = FALSE, + var.equal = TRUE, conf.level = 0.95) Two Sample t-test data: ROS_0 and ROS_1 t = -1.8, df = 790, p-value = 0.08 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -2.2948 0.1289 sample estimates: mean of x mean of y 6.741 7.824 La media campionaria nel secondo campione risulta essere maggiore, ma i risultati del test suggeriscono che non sembrano esserci differenze significative tra le medie del ROS nelle due popolazioni di aziende, quelle il cui CEO non ha un Master o un Phd e quelle in cui il CEO ha un Master o un Phd (almeno per i valori standard 1% e 5% del livello di significatività). 6.2.3.2 Campioni dipendenti In R possiamo affrontare il caso di campioni dipendenti ancora con la funzione t.test(), salvo che questa volta gli argomenti x e y devono includere lo stesso numero di osservazioni e l’argomento paired deve essere posto uguale a TRUE. Vediamo un esempio usando i dati contenuti nel data frame supermarket già discusso nella Sezione 4.3.2. Dopo aver caricato i dati, creiamo due vettori che contengono rispettivamente i dati relativi ai due campioni, con l’accortezza che il primo campione riguarderà il giorno in cui la promozione era attiva e il secondo quello in non lo era. Successivamente, con la funzione t.test() calcoliamo l’intervallo di confidenza al 90% per la differenza delle medie ed eseguiamo il test \\[\\begin{equation*} H_0: \\mu_X - \\mu_Y \\le 0 \\qquad \\mbox{vs.} \\qquad H_1: \\mu_X - \\mu_Y &gt; 0, \\end{equation*}\\] ovvero ci interessa verificare se i dati suggeriscono che la promozione ha permesso di aumentare il numero medio di visite ai negozi54. Il codice seguente consente di effettuare queste analisi: &gt; load(&quot;supermarket.RData&quot;) &gt; program_yes &lt;- supermarket$customers[supermarket$program == &quot;yes&quot;] &gt; program_no &lt;- supermarket$customers[supermarket$program == &quot;no&quot;] &gt; t.test(x = program_yes, y = program_no, alternative = &quot;greater&quot;, + paired = TRUE, conf.level = 0.90) Paired t-test data: program_yes and program_no t = 2.1, df = 9, p-value = 0.03 alternative hypothesis: true difference in means is greater than 0 90 percent confidence interval: 1.022 Inf sample estimates: mean of the differences 3 Notate che abbiamo fissato alternative = &quot;greater&quot; perché ora ci interessa un test unilaterale. I risultati indicano che, assumendo di usare un livello di significatività del 5%, la promozione sembra avere avuto un effetto significativo sulla media del numero di visite poiché il p-value del test (0.03266) è inferiore a 0.05. 6.2.4 Inferenza sull’indice di correlazione lineare In analogia con altre funzioni presentate finora (ovvero t.test() e prop.test()), R mette a disposizione la funzione cor.test() per fare inferenza sull’indice di correlazione lineare \\(\\rho\\) di una popolazione normale bivariata. Come per la funzione cor(), anche questa funzione richiede di specificare le due variabili di cui vogliamo valutare l’associazione, insieme agli argomenti alternative e conf.level comuni alle altre funzioni sopra citate. A titolo di esempio, riprendiamo il data frame forbes94 ed effettuiamo un test per valutare l’assenza di associazione lineare tra le variabili Salary e Age, ovvero \\[\\begin{equation*} H_0: \\rho_{(\\mbox{Salary}, \\mbox{Age})} = 0 \\quad \\mbox{vs.} \\quad H_1: \\rho_{(\\mbox{Salary}, \\mbox{Age})} \\ne 0. \\end{equation*}\\] Insieme al diagramma di dispersione delle due variabili, il codice seguente fornisce i risultati relativi a tale test: &gt; plot(x = forbes94$Age, y = forbes94$Salary, xlab = &quot;Age&quot;, ylab = &quot;Salary&quot;) Figura 6.14: Diagramma di dispersione per la variabile Salary contro Age. &gt; cor.test(x = forbes94$Salary, y = forbes94$Age, + alternative = &quot;two.sided&quot;, conf.level = 0.95) Pearson&#39;s product-moment correlation data: forbes94$Salary and forbes94$Age t = 6.7, df = 790, p-value = 4e-11 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: 0.1654 0.2975 sample estimates: cor 0.2325 L’indice di correlazione campionario tra le due variabili, pari a 0.2353, segnala un’associazione lineare debole, ma il basso valore del p-value (3.788e-11) evidenzia che tale associazione è altamente significativa. Ricordiamo che tale notazione rappresenta un modo alternativo per indicare numeri molto vicini a zero, in questo caso \\(3.377 \\times 10^{-5} = 0.00003377\\).↩ Ricordate che R converte internamente il valore logico FALSE in 0 e il valore logico TRUE in 1.↩ Questi valori non corrispondono esattamente al calcolo che abbiamo presentato nel corso, perché R internamente usa una formula leggermente diversa, ma più precisa. Ricordatevi infatti che le espressioni che abbiamo visto in questo caso sono delle approssimazioni basate sulla distribuzione normale.↩ Nel test \\(X\\) indica la popolazione di negozi in cui la promozione è attiva, mentre \\(Y\\) denota la popolazione di negozi in cui la promozione non è attiva.↩ "]
]
